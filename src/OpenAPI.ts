/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */

export interface paths {
  "/Experimental": {
    /**
     * Experimental
     * @description Experimental node.
     */
    post: operations["Experimental"];
  };
  "/RunPython": {
    /**
     * RunPython
     * @description Run code using a Python interpreter.
     */
    post: operations["RunPython"];
  };
  "/GenerateText": {
    /**
     * GenerateText
     * @description Generate text using a language model.
     */
    post: operations["GenerateText"];
  };
  "/MultiGenerateText": {
    /**
     * MultiGenerateText
     * @description Generate multiple text choices using a language model.
     */
    post: operations["MultiGenerateText"];
  };
  "/BatchGenerateText": {
    /**
     * BatchGenerateText
     * @description Generate text for multiple prompts in batch using a language model.
     */
    post: operations["BatchGenerateText"];
  };
  "/BatchGenerateJSON": {
    /**
     * BatchGenerateJSON
     * @description Generate JSON for multiple prompts in batch using a language model.
     */
    post: operations["BatchGenerateJSON"];
  };
  "/GenerateJSON": {
    /**
     * GenerateJSON
     * @description Generate JSON using a language model.
     */
    post: operations["GenerateJSON"];
  };
  "/MultiGenerateJSON": {
    /**
     * MultiGenerateJSON
     * @description Generate multiple JSON choices using a language model.
     */
    post: operations["MultiGenerateJSON"];
  };
  "/Mistral7BInstruct": {
    /**
     * Mistral7BInstruct
     * @description Generate text using [Mistral 7B Instruct](https://mistral.ai/news/announcing-mistral-7b).
     */
    post: operations["Mistral7BInstruct"];
  };
  "/Mixtral8x7BInstruct": {
    /**
     * Mixtral8x7BInstruct
     * @description Generate text using instruct-tuned [Mixtral 8x7B](https://mistral.ai/news/mixtral-of-experts/).
     */
    post: operations["Mixtral8x7BInstruct"];
  };
  "/Llama3Instruct8B": {
    /**
     * Llama3Instruct8B
     * @description Generate text using instruct-tuned [Llama 3 8B](https://llama.meta.com/llama3/).
     */
    post: operations["Llama3Instruct8B"];
  };
  "/Llama3Instruct70B": {
    /**
     * Llama3Instruct70B
     * @description Generate text using instruct-tuned [Llama 3 70B](https://llama.meta.com/llama3/).
     */
    post: operations["Llama3Instruct70B"];
  };
  "/Firellava13B": {
    /**
     * Firellava13B
     * @description Generate text with image input using [FireLLaVA 13B](https://fireworks.ai/blog/firellava-the-first-commercially-permissive-oss-llava-model).
     */
    post: operations["Firellava13B"];
  };
  "/GenerateImage": {
    /**
     * GenerateImage
     * @description Generate an image.
     */
    post: operations["GenerateImage"];
  };
  "/MultiGenerateImage": {
    /**
     * MultiGenerateImage
     * @description Generate multiple images.
     */
    post: operations["MultiGenerateImage"];
  };
  "/InpaintImage": {
    /**
     * InpaintImage
     * @description Edit an image using image generation inside part of the image or the full image.
     */
    post: operations["InpaintImage"];
  };
  "/MultiInpaintImage": {
    /**
     * MultiInpaintImage
     * @description Edit multiple images using image generation.
     */
    post: operations["MultiInpaintImage"];
  };
  "/StableDiffusionXLLightning": {
    /**
     * StableDiffusionXLLightning
     * @description Generate an image using [Stable Diffusion XL Lightning](https://arxiv.org/abs/2402.13929).
     */
    post: operations["StableDiffusionXLLightning"];
  };
  "/StableDiffusionXLInpaint": {
    /**
     * StableDiffusionXLInpaint
     * @description Edit an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952). Supports inpainting (edit part of the image with a mask) and image-to-image (edit the full image).
     */
    post: operations["StableDiffusionXLInpaint"];
  };
  "/StableDiffusionXLControlNet": {
    /**
     * StableDiffusionXLControlNet
     * @description Generate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543).
     */
    post: operations["StableDiffusionXLControlNet"];
  };
  "/TranscribeSpeech": {
    /**
     * TranscribeSpeech
     * @description Transcribe speech in an audio or video file.
     */
    post: operations["TranscribeSpeech"];
  };
  "/GenerateSpeech": {
    /**
     * GenerateSpeech
     * @description Generate speech from text.
     */
    post: operations["GenerateSpeech"];
  };
  "/RemoveBackground": {
    /**
     * RemoveBackground
     * @description Remove the background from an image and return the foreground segment as a cut-out or a mask.
     */
    post: operations["RemoveBackground"];
  };
  "/EraseImage": {
    /**
     * EraseImage
     * @description Erase the masked part of an image, e.g. to 'remove' an object.
     */
    post: operations["EraseImage"];
  };
  "/UpscaleImage": {
    /**
     * UpscaleImage
     * @description Upscale an image using image generation.
     */
    post: operations["UpscaleImage"];
  };
  "/SegmentUnderPoint": {
    /**
     * SegmentUnderPoint
     * @description Segment an image under a point and return the segment.
     */
    post: operations["SegmentUnderPoint"];
  };
  "/SegmentAnything": {
    /**
     * SegmentAnything
     * @description Segment an image using [SegmentAnything](https://github.com/facebookresearch/segment-anything).
     */
    post: operations["SegmentAnything"];
  };
  "/EmbedText": {
    /**
     * EmbedText
     * @description Generate embedding for a text document.
     */
    post: operations["EmbedText"];
  };
  "/MultiEmbedText": {
    /**
     * MultiEmbedText
     * @description Generate embeddings for multiple text documents.
     */
    post: operations["MultiEmbedText"];
  };
  "/EmbedImage": {
    /**
     * EmbedImage
     * @description Generate embedding for an image.
     */
    post: operations["EmbedImage"];
  };
  "/MultiEmbedImage": {
    /**
     * MultiEmbedImage
     * @description Generate embeddings for multiple images.
     */
    post: operations["MultiEmbedImage"];
  };
  "/JinaV2": {
    /**
     * JinaV2
     * @description Generate embeddings for multiple text documents using [Jina Embeddings 2](https://arxiv.org/abs/2310.19923).
     */
    post: operations["JinaV2"];
  };
  "/CLIP": {
    /**
     * CLIP
     * @description Generate embeddings for text or images using [CLIP](https://openai.com/research/clip).
     */
    post: operations["CLIP"];
  };
  "/FindOrCreateVectorStore": {
    /**
     * FindOrCreateVectorStore
     * @description Find a vector store matching the given collection name, or create a new vector store.
     */
    post: operations["FindOrCreateVectorStore"];
  };
  "/ListVectorStores": {
    /**
     * ListVectorStores
     * @description List all vector stores.
     */
    post: operations["ListVectorStores"];
  };
  "/DeleteVectorStore": {
    /**
     * DeleteVectorStore
     * @description Delete a vector store.
     */
    post: operations["DeleteVectorStore"];
  };
  "/QueryVectorStore": {
    /**
     * QueryVectorStore
     * @description Query a vector store for similar vectors.
     */
    post: operations["QueryVectorStore"];
  };
  "/FetchVectors": {
    /**
     * FetchVectors
     * @description Fetch vectors from a vector store.
     */
    post: operations["FetchVectors"];
  };
  "/UpdateVectors": {
    /**
     * UpdateVectors
     * @description Update vectors in a vector store.
     */
    post: operations["UpdateVectors"];
  };
  "/DeleteVectors": {
    /**
     * DeleteVectors
     * @description Delete vectors in a vector store.
     */
    post: operations["DeleteVectors"];
  };
}

export type webhooks = Record<string, never>;

export interface components {
  schemas: {
    /** ErrorOut */
    ErrorOut: {
      /**
       * @description The type of error returned.
       * @enum {string}
       */
      type: "api_error" | "invalid_request_error";
      /** @description A message providing more details about the error. */
      message: string;
    };
    /** ExperimentalIn */
    ExperimentalIn: {
      /** @description Identifier. */
      name: string;
      /** @description Arguments. */
      args: {
        [key: string]: unknown;
      };
      /**
       * @description Timeout in seconds.
       * @default 60
       */
      timeout?: number;
    };
    /** ExperimentalOut */
    ExperimentalOut: {
      /** @description Response. */
      output: {
        [key: string]: unknown;
      };
    };
    /** RunPythonIn */
    RunPythonIn: {
      /** @description Pickled function. */
      pkl_function?: string;
      /** @description Keyword arguments to your function. */
      kwargs: {
        [key: string]: unknown;
      };
      /** @description Python version. */
      python_version?: string;
      /** @description Python packages to install. You must import them in your code. */
      pip_install?: string[];
    };
    /** RunPythonOut */
    RunPythonOut: {
      /** @description Return value of your function. */
      output?: unknown;
      /** @description Pickled return value. */
      pkl_output?: string;
      /** @description Everything printed to stdout while running your code. */
      stdout: string;
      /** @description Contents of stderr if your code did not run successfully. */
      stderr: string;
    };
    /** GenerateTextIn */
    GenerateTextIn: {
      /** @description Input prompt. */
      prompt: string;
      /** @description Image prompts. */
      image_uris?: string[];
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
       * @default 0.4
       */
      temperature?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
      /**
       * @description Selected model. `Firellava13B` is automatically selected when `image_uris` is provided.
       * @default Llama3Instruct8B
       * @enum {string}
       */
      model?:
        | "Mistral7BInstruct"
        | "Mixtral8x7BInstruct"
        | "Llama3Instruct8B"
        | "Llama3Instruct70B"
        | "Firellava13B";
    };
    /** GenerateTextOut */
    GenerateTextOut: {
      /** @description Text response. */
      text: string;
    };
    /** GenerateJSONIn */
    GenerateJSONIn: {
      /** @description Input prompt. */
      prompt: string;
      /** @description JSON schema to guide `json_object` response. */
      json_schema: {
        [key: string]: unknown;
      };
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
       * @default 0.4
       */
      temperature?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
      /**
       * @description Selected model.
       * @default Llama3Instruct8B
       * @enum {string}
       */
      model?: "Mistral7BInstruct" | "Mixtral8x7BInstruct" | "Llama3Instruct8B";
    };
    /** GenerateJSONOut */
    GenerateJSONOut: {
      /** @description JSON response. */
      json_object?: {
        [key: string]: unknown;
      };
      /** @description If the model output could not be parsed to JSON, this is the raw text output. */
      text?: string;
    };
    /** MultiGenerateTextIn */
    MultiGenerateTextIn: {
      /** @description Input prompt. */
      prompt: string;
      /**
       * @description Number of choices to generate.
       * @default 1
       */
      num_choices: number;
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
       * @default 0.4
       */
      temperature?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
      /**
       * @description Selected model.
       * @default Llama3Instruct8B
       * @enum {string}
       */
      model?:
        | "Mistral7BInstruct"
        | "Mixtral8x7BInstruct"
        | "Llama3Instruct8B"
        | "Llama3Instruct70B";
    };
    /** MultiGenerateTextOut */
    MultiGenerateTextOut: {
      /** @description Response choices. */
      choices: {
        /** @description Text response. */
        text: string;
      }[];
    };
    /** BatchGenerateTextIn */
    BatchGenerateTextIn: {
      /** @description Batch input prompts. */
      prompts: string[];
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
       * @default 0.4
       */
      temperature?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
      /**
       * @description Selected model.
       * @default Llama3Instruct8B
       * @enum {string}
       */
      model?: "Mistral7BInstruct" | "Llama3Instruct8B";
    };
    /** BatchGenerateTextOut */
    BatchGenerateTextOut: {
      /** @description Batch outputs. */
      outputs: {
        /** @description Text response. */
        text: string;
      }[];
    };
    /** MultiGenerateJSONIn */
    MultiGenerateJSONIn: {
      /** @description Input prompt. */
      prompt: string;
      /** @description JSON schema to guide `json_object` response. */
      json_schema: {
        [key: string]: unknown;
      };
      /**
       * @description Number of choices to generate.
       * @default 2
       */
      num_choices: number;
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
       * @default 0.4
       */
      temperature?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
      /**
       * @description Selected model.
       * @default Llama3Instruct8B
       * @enum {string}
       */
      model?: "Mistral7BInstruct" | "Mixtral8x7BInstruct" | "Llama3Instruct8B";
    };
    /** MultiGenerateJSONOut */
    MultiGenerateJSONOut: {
      /** @description Response choices. */
      choices: {
        /** @description JSON response. */
        json_object?: {
          [key: string]: unknown;
        };
        /** @description If the model output could not be parsed to JSON, this is the raw text output. */
        text?: string;
      }[];
    };
    /** BatchGenerateJSONIn */
    BatchGenerateJSONIn: {
      /** @description Batch input prompts. */
      prompts: string[];
      /** @description JSON schema to guide `json_object` response. */
      json_schema: {
        [key: string]: unknown;
      };
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
       * @default 0.4
       */
      temperature?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
      /**
       * @description Selected model.
       * @default Llama3Instruct8B
       * @enum {string}
       */
      model?: "Mistral7BInstruct" | "Llama3Instruct8B";
    };
    /** BatchGenerateJSONOut */
    BatchGenerateJSONOut: {
      /** @description Batch outputs. */
      outputs: {
        /** @description JSON response. */
        json_object?: {
          [key: string]: unknown;
        };
        /** @description If the model output could not be parsed to JSON, this is the raw text output. */
        text?: string;
      }[];
    };
    /** Mistral7BInstructIn */
    Mistral7BInstructIn: {
      /** @description Input prompt. */
      prompt: string;
      /** @description System prompt. */
      system_prompt?: string;
      /**
       * @description Number of choices to generate.
       * @default 1
       */
      num_choices?: number;
      /** @description JSON schema to guide response. */
      json_schema?: {
        [key: string]: unknown;
      };
      /**
       * Format: float
       * @description Higher values make the output more random, lower values make the output more deterministic.
       */
      temperature?: number;
      /**
       * Format: float
       * @description Higher values decrease the likelihood of repeating previous tokens.
       * @default 0
       */
      frequency_penalty?: number;
      /**
       * Format: float
       * @description Higher values decrease the likelihood of repeated sequences.
       * @default 1
       */
      repetition_penalty?: number;
      /**
       * Format: float
       * @description Higher values increase the likelihood of new topics appearing.
       * @default 1.1
       */
      presence_penalty?: number;
      /**
       * Format: float
       * @description Probability below which less likely tokens are filtered out.
       * @default 0.95
       */
      top_p?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
    };
    /** Mistral7BInstructChoice */
    Mistral7BInstructChoice: {
      /** @description Text response, if `json_schema` was not provided. */
      text?: string;
      /** @description JSON response, if `json_schema` was provided. */
      json_object?: {
        [key: string]: unknown;
      };
    };
    /** Mistral7BInstructOut */
    Mistral7BInstructOut: {
      /** @description Response choices. */
      choices: {
        /** @description Text response, if `json_schema` was not provided. */
        text?: string;
        /** @description JSON response, if `json_schema` was provided. */
        json_object?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** Mixtral8x7BInstructIn */
    Mixtral8x7BInstructIn: {
      /** @description Input prompt. */
      prompt: string;
      /** @description System prompt. */
      system_prompt?: string;
      /**
       * @description Number of choices to generate.
       * @default 1
       */
      num_choices?: number;
      /** @description JSON schema to guide response. */
      json_schema?: {
        [key: string]: unknown;
      };
      /**
       * Format: float
       * @description Higher values make the output more random, lower values make the output more deterministic.
       */
      temperature?: number;
      /**
       * Format: float
       * @description Higher values decrease the likelihood of repeating previous tokens.
       * @default 0
       */
      frequency_penalty?: number;
      /**
       * Format: float
       * @description Higher values decrease the likelihood of repeated sequences.
       * @default 1
       */
      repetition_penalty?: number;
      /**
       * Format: float
       * @description Higher values increase the likelihood of new topics appearing.
       * @default 1.1
       */
      presence_penalty?: number;
      /**
       * Format: float
       * @description Probability below which less likely tokens are filtered out.
       * @default 0.95
       */
      top_p?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
    };
    /** Mixtral8x7BChoice */
    Mixtral8x7BChoice: {
      /** @description Text response, if `json_schema` was not provided. */
      text?: string;
      /** @description JSON response, if `json_schema` was provided. */
      json_object?: {
        [key: string]: unknown;
      };
    };
    /** Mixtral8x7BInstructOut */
    Mixtral8x7BInstructOut: {
      /** @description Response choices. */
      choices: {
        /** @description Text response, if `json_schema` was not provided. */
        text?: string;
        /** @description JSON response, if `json_schema` was provided. */
        json_object?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** Llama3Instruct8BIn */
    Llama3Instruct8BIn: {
      /** @description Input prompt. */
      prompt: string;
      /** @description System prompt. */
      system_prompt?: string;
      /**
       * @description Number of choices to generate.
       * @default 1
       */
      num_choices?: number;
      /**
       * Format: float
       * @description Higher values make the output more random, lower values make the output more deterministic.
       */
      temperature?: number;
      /**
       * Format: float
       * @description Higher values decrease the likelihood of repeating previous tokens.
       * @default 0
       */
      frequency_penalty?: number;
      /**
       * Format: float
       * @description Higher values decrease the likelihood of repeated sequences.
       * @default 1
       */
      repetition_penalty?: number;
      /**
       * Format: float
       * @description Higher values increase the likelihood of new topics appearing.
       * @default 1.1
       */
      presence_penalty?: number;
      /**
       * Format: float
       * @description Probability below which less likely tokens are filtered out.
       * @default 0.95
       */
      top_p?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
      /** @description JSON schema to guide response. */
      json_schema?: {
        [key: string]: unknown;
      };
    };
    /** Llama3Instruct8BChoice */
    Llama3Instruct8BChoice: {
      /** @description Text response. */
      text?: string;
      /** @description JSON response, if `json_schema` was provided. */
      json_object?: {
        [key: string]: unknown;
      };
    };
    /** Llama3Instruct8BOut */
    Llama3Instruct8BOut: {
      /** @description Response choices. */
      choices: {
        /** @description Text response. */
        text?: string;
        /** @description JSON response, if `json_schema` was provided. */
        json_object?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** Llama3Instruct70BIn */
    Llama3Instruct70BIn: {
      /** @description Input prompt. */
      prompt: string;
      /** @description System prompt. */
      system_prompt?: string;
      /**
       * @description Number of choices to generate.
       * @default 1
       */
      num_choices?: number;
      /**
       * Format: float
       * @description Higher values make the output more random, lower values make the output more deterministic.
       */
      temperature?: number;
      /**
       * Format: float
       * @description Higher values decrease the likelihood of repeating previous tokens.
       * @default 0
       */
      frequency_penalty?: number;
      /**
       * Format: float
       * @description Higher values decrease the likelihood of repeated sequences.
       * @default 1
       */
      repetition_penalty?: number;
      /**
       * Format: float
       * @description Higher values increase the likelihood of new topics appearing.
       * @default 1.1
       */
      presence_penalty?: number;
      /**
       * Format: float
       * @description Probability below which less likely tokens are filtered out.
       * @default 0.95
       */
      top_p?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
    };
    /** Llama3Instruct70BChoice */
    Llama3Instruct70BChoice: {
      /** @description Text response. */
      text?: string;
    };
    /** Llama3Instruct70BOut */
    Llama3Instruct70BOut: {
      /** @description Response choices. */
      choices: {
        /** @description Text response. */
        text?: string;
      }[];
    };
    /** Firellava13BIn */
    Firellava13BIn: {
      /** @description Text prompt. */
      prompt: string;
      /** @description Image prompts. */
      image_uris: string[];
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
    };
    /** Firellava13BOut */
    Firellava13BOut: {
      /** @description Text response. */
      text: string;
    };
    /** GenerateImageIn */
    GenerateImageIn: {
      /** @description Text prompt. */
      prompt: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** GenerateImageOut */
    GenerateImageOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** MultiGenerateImageIn */
    MultiGenerateImageIn: {
      /** @description Text prompt. */
      prompt: string;
      /**
       * @description Number of images to generate.
       * @default 2
       */
      num_images: number;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** MultiGenerateImageOut */
    MultiGenerateImageOut: {
      /** @description Generated images. */
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
      }[];
    };
    /** StableDiffusionXLIn */
    StableDiffusionXLIn: {
      /** @description Text prompt. */
      prompt: string;
      /** @description Negative input prompt. */
      negative_prompt?: string;
      /**
       * @description Number of diffusion steps.
       * @default 30
       */
      steps?: number;
      /**
       * @description Number of images to generate.
       * @default 1
       */
      num_images: number;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * @description Height of output image, in pixels.
       * @default 1024
       */
      height?: number;
      /**
       * @description Width of output image, in pixels.
       * @default 1024
       */
      width?: number;
      /** @description Seeds for deterministic generation. Default is a random seed. */
      seeds?: number[];
      /**
       * Format: float
       * @description Higher values adhere to the text prompt more strongly, typically at the expense of image quality.
       * @default 7
       */
      guidance_scale?: number;
    };
    /** StableDiffusionImage */
    StableDiffusionImage: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
      /** @description The random noise seed used for generation. */
      seed: number;
    };
    /** StableDiffusionXLOut */
    StableDiffusionXLOut: {
      /** @description Generated images. */
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
        /** @description The random noise seed used for generation. */
        seed: number;
      }[];
    };
    /** StableDiffusionXLLightningIn */
    StableDiffusionXLLightningIn: {
      /** @description Text prompt. */
      prompt: string;
      /** @description Negative input prompt. */
      negative_prompt?: string;
      /**
       * @description Number of images to generate.
       * @default 1
       */
      num_images?: number;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * @description Height of output image, in pixels.
       * @default 1024
       */
      height?: number;
      /**
       * @description Width of output image, in pixels.
       * @default 1024
       */
      width?: number;
      /** @description Seeds for deterministic generation. Default is a random seed. */
      seeds?: number[];
    };
    /** StableDiffusionXLLightningOut */
    StableDiffusionXLLightningOut: {
      /** @description Generated images. */
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
        /** @description The random noise seed used for generation. */
        seed: number;
      }[];
    };
    /** StableDiffusionXLIPAdapterIn */
    StableDiffusionXLIPAdapterIn: {
      /** @description Text prompt. */
      prompt: string;
      /** @description Image prompt. */
      image_prompt_uri: string;
      /**
       * @description Number of images to generate.
       * @default 1
       */
      num_images: number;
      /**
       * Format: float
       * @description Controls the influence of the image prompt on the generated output.
       * @default 0.5
       */
      ip_adapter_scale?: number;
      /** @description Negative input prompt. */
      negative_prompt?: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * @description Width of output image, in pixels.
       * @default 1024
       */
      width?: number;
      /**
       * @description Height of output image, in pixels.
       * @default 1024
       */
      height?: number;
      /** @description Random noise seeds. Default is random seeds for each generation. */
      seeds?: number[];
    };
    /** StableDiffusionXLIPAdapterOut */
    StableDiffusionXLIPAdapterOut: {
      /** @description Generated images. */
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
        /** @description The random noise seed used for generation. */
        seed: number;
      }[];
    };
    /** StableDiffusionXLControlNetIn */
    StableDiffusionXLControlNetIn: {
      /** @description Input image. */
      image_uri: string;
      /**
       * @description Strategy to control generation using the input image.
       * @enum {string}
       */
      control_method: "edge" | "depth" | "illusion" | "tile";
      /** @description Text prompt. */
      prompt: string;
      /**
       * @description Number of images to generate.
       * @default 1
       */
      num_images: number;
      /**
       * @description Resolution of the output image, in pixels.
       * @default 1024
       */
      output_resolution?: number;
      /** @description Negative input prompt. */
      negative_prompt?: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * Format: float
       * @description Controls the influence of the input image on the generated output.
       * @default 0.5
       */
      conditioning_scale?: number;
      /**
       * Format: float
       * @description Controls how much to transform the input image.
       * @default 0.5
       */
      strength?: number;
      /** @description Random noise seeds. Default is random seeds for each generation. */
      seeds?: number[];
    };
    /** StableDiffusionXLControlNetOut */
    StableDiffusionXLControlNetOut: {
      /** @description Generated images. */
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
        /** @description The random noise seed used for generation. */
        seed: number;
      }[];
    };
    /** InpaintImageIn */
    InpaintImageIn: {
      /** @description Original image. */
      image_uri: string;
      /** @description Text prompt. */
      prompt: string;
      /** @description Mask image that controls which pixels are inpainted. If unset, the entire image is edited (image-to-image). */
      mask_image_uri?: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** InpaintImageOut */
    InpaintImageOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** MultiInpaintImageIn */
    MultiInpaintImageIn: {
      /** @description Original image. */
      image_uri: string;
      /** @description Text prompt. */
      prompt: string;
      /** @description Mask image that controls which pixels are edited (inpainting). If unset, the entire image is edited (image-to-image). */
      mask_image_uri?: string;
      /**
       * @description Number of images to generate.
       * @default 2
       */
      num_images: number;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** MultiInpaintImageOut */
    MultiInpaintImageOut: {
      /** @description Generated images. */
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
      }[];
    };
    /** StableDiffusionXLInpaintIn */
    StableDiffusionXLInpaintIn: {
      /** @description Original image. */
      image_uri: string;
      /** @description Text prompt. */
      prompt: string;
      /** @description Mask image that controls which pixels are edited (inpainting). If unset, the entire image is edited (image-to-image). */
      mask_image_uri?: string;
      /**
       * @description Number of images to generate.
       * @default 1
       */
      num_images: number;
      /**
       * @description Resolution of the output image, in pixels.
       * @default 1024
       */
      output_resolution?: number;
      /** @description Negative input prompt. */
      negative_prompt?: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * Format: float
       * @description Controls the strength of the generation process.
       * @default 0.8
       */
      strength?: number;
      /** @description Random noise seeds. Default is random seeds for each generation. */
      seeds?: number[];
    };
    /** StableDiffusionXLInpaintOut */
    StableDiffusionXLInpaintOut: {
      /** @description Generated images. */
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
        /** @description The random noise seed used for generation. */
        seed: number;
      }[];
    };
    /** BoundingBox */
    BoundingBox: {
      /**
       * Format: float
       * @description Top left corner x.
       */
      x1: number;
      /**
       * Format: float
       * @description Top left corner y.
       */
      y1: number;
      /**
       * Format: float
       * @description Bottom right corner x.
       */
      x2: number;
      /**
       * Format: float
       * @description Bottom right corner y.
       */
      y2: number;
    };
    /** Point */
    Point: {
      /** @description X position. */
      x: number;
      /** @description Y position. */
      y: number;
    };
    /** EraseImageIn */
    EraseImageIn: {
      /** @description Input image. */
      image_uri: string;
      /** @description Mask image that controls which pixels are inpainted. */
      mask_image_uri: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** EraseImageOut */
    EraseImageOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** BigLaMaIn */
    BigLaMaIn: {
      /** @description Input image. */
      image_uri: string;
      /** @description Mask image that controls which pixels are inpainted. */
      mask_image_uri: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** BigLaMaOut */
    BigLaMaOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** RemoveBackgroundIn */
    RemoveBackgroundIn: {
      /** @description Input image. */
      image_uri: string;
      /**
       * @description Return a mask image instead of the original content.
       * @default false
       */
      return_mask?: boolean;
      /** @description Hex value background color. Transparent if unset. */
      background_color?: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** RemoveBackgroundOut */
    RemoveBackgroundOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** DISISNetIn */
    DISISNetIn: {
      /** @description Input image. */
      image_uri: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** DISISNetOut */
    DISISNetOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** UpscaleImageIn */
    UpscaleImageIn: {
      /** @description Prompt to guide model on the content of image to upscale. */
      prompt?: string;
      /** @description Input image. */
      image_uri: string;
      /**
       * @description Resolution of the output image, in pixels.
       * @default 1024
       */
      output_resolution?: number;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** UpscaleImageOut */
    UpscaleImageOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** SegmentUnderPointIn */
    SegmentUnderPointIn: {
      /** @description Input image. */
      image_uri: string;
      /** Point */
      point: {
        /** @description X position. */
        x: number;
        /** @description Y position. */
        y: number;
      };
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** SegmentUnderPointOut */
    SegmentUnderPointOut: {
      /** @description Detected segments in 'mask image' format. Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      mask_image_uri: string;
    };
    /** SegmentAnythingIn */
    SegmentAnythingIn: {
      /** @description Input image. */
      image_uri: string;
      /** @description Point prompts, to detect a segment under the point. One of `point_prompts` or `box_prompts` must be set. */
      point_prompts?: {
        /** @description X position. */
        x: number;
        /** @description Y position. */
        y: number;
      }[];
      /** @description Box prompts, to detect a segment within the bounding box. One of `point_prompts` or `box_prompts` must be set. */
      box_prompts?: {
        /**
         * Format: float
         * @description Top left corner x.
         */
        x1: number;
        /**
         * Format: float
         * @description Top left corner y.
         */
        y1: number;
        /**
         * Format: float
         * @description Bottom right corner x.
         */
        x2: number;
        /**
         * Format: float
         * @description Bottom right corner y.
         */
        y2: number;
      }[];
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** SegmentAnythingOut */
    SegmentAnythingOut: {
      /** @description Detected segments in 'mask image' format. Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      mask_image_uri: string;
    };
    /** TranscribeSpeechIn */
    TranscribeSpeechIn: {
      /** @description Input audio. */
      audio_uri: string;
      /** @description Prompt to guide model on the content and context of input audio. */
      prompt?: string;
      /**
       * @description Language of input audio in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes) format.
       * @default en
       */
      language?: string;
      /**
       * @description Segment the text into sentences with approximate timestamps.
       * @default false
       */
      segment?: boolean;
      /**
       * @description Align transcription to produce more accurate sentence-level timestamps and word-level timestamps. An array of word segments will be included in each sentence segment.
       * @default false
       */
      align?: boolean;
      /**
       * @description Identify speakers for each segment. Speaker IDs will be included in each segment.
       * @default false
       */
      diarize?: boolean;
      /**
       * @description Suggest automatic chapter markers.
       * @default false
       */
      suggest_chapters?: boolean;
    };
    /** TranscribedWord */
    TranscribedWord: {
      /** @description Text of word. */
      word: string;
      /**
       * Format: float
       * @description Start time of word, in seconds.
       */
      start?: number;
      /**
       * Format: float
       * @description End time of word, in seconds.
       */
      end?: number;
      /** @description ID of speaker, if `diarize` is enabled. */
      speaker?: string;
    };
    /** TranscribedSegment */
    TranscribedSegment: {
      /** @description Text of segment. */
      text: string;
      /**
       * Format: float
       * @description Start time of segment, in seconds.
       */
      start: number;
      /**
       * Format: float
       * @description End time of segment, in seconds.
       */
      end: number;
      /** @description ID of speaker, if `diarize` is enabled. */
      speaker?: string;
      /** @description Aligned words, if `align` is enabled. */
      words?: {
        /** @description Text of word. */
        word: string;
        /**
         * Format: float
         * @description Start time of word, in seconds.
         */
        start?: number;
        /**
         * Format: float
         * @description End time of word, in seconds.
         */
        end?: number;
        /** @description ID of speaker, if `diarize` is enabled. */
        speaker?: string;
      }[];
    };
    /** ChapterMarker */
    ChapterMarker: {
      /** @description Chapter title. */
      title: string;
      /**
       * Format: float
       * @description Start time of chapter, in seconds.
       */
      start: number;
    };
    /** TranscribeSpeechOut */
    TranscribeSpeechOut: {
      /** @description Transcribed text. */
      text: string;
      /** @description Transcribed segments, if `segment` is enabled. */
      segments?: {
        /** @description Text of segment. */
        text: string;
        /**
         * Format: float
         * @description Start time of segment, in seconds.
         */
        start: number;
        /**
         * Format: float
         * @description End time of segment, in seconds.
         */
        end: number;
        /** @description ID of speaker, if `diarize` is enabled. */
        speaker?: string;
        /** @description Aligned words, if `align` is enabled. */
        words?: {
          /** @description Text of word. */
          word: string;
          /**
           * Format: float
           * @description Start time of word, in seconds.
           */
          start?: number;
          /**
           * Format: float
           * @description End time of word, in seconds.
           */
          end?: number;
          /** @description ID of speaker, if `diarize` is enabled. */
          speaker?: string;
        }[];
      }[];
      /** @description Chapter markers, if `suggest_chapters` is enabled. */
      chapters?: {
        /** @description Chapter title. */
        title: string;
        /**
         * Format: float
         * @description Start time of chapter, in seconds.
         */
        start: number;
      }[];
    };
    /** GenerateSpeechIn */
    GenerateSpeechIn: {
      /** @description Input text. */
      text: string;
      /** @description Use "hosted" to return an audio URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the audio data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** GenerateSpeechOut */
    GenerateSpeechOut: {
      /** @description Base 64-encoded WAV audio bytes, or a hosted audio url if `store` is provided. */
      audio_uri: string;
    };
    /** XTTSV2In */
    XTTSV2In: {
      /** @description Input text. */
      text: string;
      /** @description Reference audio used to synthesize the speaker. If unset, a default speaker voice will be used. */
      audio_uri?: string;
      /**
       * @description Language of input text. Supported languages: `en, de, fr, es, it, pt, pl, zh, ar, cs, ru, nl, tr, hu, ko`.
       * @default en
       */
      language?: string;
      /** @description Use "hosted" to return an audio URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the audio data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** XTTSV2Out */
    XTTSV2Out: {
      /** @description Base 64-encoded WAV audio bytes, or a hosted audio url if `store` is provided. */
      audio_uri: string;
    };
    /** Embedding */
    Embedding: {
      /** @description Embedding vector. */
      vector: number[];
      /** @description Vector store document ID. */
      doc_id?: string;
      /** @description Vector store document metadata. */
      metadata?: {
        [key: string]: unknown;
      };
    };
    /** EmbedTextIn */
    EmbedTextIn: {
      /** @description Text to embed. */
      text: string;
      /** @description Vector store name. */
      collection_name?: string;
      /** @description Metadata that can be used to query the vector store. Ignored if `collection_name` is unset. */
      metadata?: {
        [key: string]: unknown;
      };
      /** @description Choose keys from `metadata` to embed with text. */
      embedded_metadata_keys?: string[];
      /** @description Vector store document ID. Ignored if `store` is unset. */
      doc_id?: string;
      /**
       * @description Selected embedding model.
       * @default jina-v2
       * @enum {string}
       */
      model?: "jina-v2" | "clip";
    };
    /** EmbedTextOut */
    EmbedTextOut: {
      /** Embedding */
      embedding: {
        /** @description Embedding vector. */
        vector: number[];
        /** @description Vector store document ID. */
        doc_id?: string;
        /** @description Vector store document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      };
    };
    /** EmbedTextItem */
    EmbedTextItem: {
      /** @description Text to embed. */
      text: string;
      /** @description Metadata that can be used to query the vector store. Ignored if `collection_name` is unset. */
      metadata?: {
        [key: string]: unknown;
      };
      /** @description Vector store document ID. Ignored if `collection_name` is unset. */
      doc_id?: string;
    };
    /** MultiEmbedTextIn */
    MultiEmbedTextIn: {
      /** @description Items to embed. */
      items: {
        /** @description Text to embed. */
        text: string;
        /** @description Metadata that can be used to query the vector store. Ignored if `collection_name` is unset. */
        metadata?: {
          [key: string]: unknown;
        };
        /** @description Vector store document ID. Ignored if `collection_name` is unset. */
        doc_id?: string;
      }[];
      /** @description Vector store name. */
      collection_name?: string;
      /** @description Choose keys from `metadata` to embed with text. */
      embedded_metadata_keys?: string[];
      /**
       * @description Selected embedding model.
       * @default jina-v2
       * @enum {string}
       */
      model?: "jina-v2" | "clip";
    };
    /** MultiEmbedTextOut */
    MultiEmbedTextOut: {
      /** @description Generated embeddings. */
      embeddings: {
        /** @description Embedding vector. */
        vector: number[];
        /** @description Vector store document ID. */
        doc_id?: string;
        /** @description Vector store document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** JinaV2In */
    JinaV2In: {
      /** @description Items to embed. */
      items: {
        /** @description Text to embed. */
        text: string;
        /** @description Metadata that can be used to query the vector store. Ignored if `collection_name` is unset. */
        metadata?: {
          [key: string]: unknown;
        };
        /** @description Vector store document ID. Ignored if `collection_name` is unset. */
        doc_id?: string;
      }[];
      /** @description Vector store name. */
      collection_name?: string;
      /** @description Choose keys from `metadata` to embed with text. */
      embedded_metadata_keys?: string[];
    };
    /** JinaV2Out */
    JinaV2Out: {
      /** @description Generated embeddings. */
      embeddings: {
        /** @description Embedding vector. */
        vector: number[];
        /** @description Vector store document ID. */
        doc_id?: string;
        /** @description Vector store document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** EmbedImageIn */
    EmbedImageIn: {
      /** @description Image to embed. */
      image_uri: string;
      /** @description Vector store name. */
      collection_name?: string;
      /** @description Vector store document ID. Ignored if `collection_name` is unset. */
      doc_id?: string;
      /**
       * @description Selected embedding model.
       * @default clip
       * @enum {string}
       */
      model?: "clip";
    };
    /** EmbedImageOut */
    EmbedImageOut: {
      /** Embedding */
      embedding: {
        /** @description Embedding vector. */
        vector: number[];
        /** @description Vector store document ID. */
        doc_id?: string;
        /** @description Vector store document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      };
    };
    /** EmbedImageItem */
    EmbedImageItem: {
      /** @description Image to embed. */
      image_uri: string;
      /** @description Vector store document ID. Ignored if `collection_name` is unset. */
      doc_id?: string;
    };
    /** EmbedTextOrImageItem */
    EmbedTextOrImageItem: {
      /** @description Image to embed. */
      image_uri?: string;
      /** @description Text to embed. */
      text?: string;
      /** @description Metadata that can be used to query the vector store. Ignored if `collection_name` is unset. */
      metadata?: {
        [key: string]: unknown;
      };
      /** @description Vector store document ID. Ignored if `collection_name` is unset. */
      doc_id?: string;
    };
    /** MultiEmbedImageIn */
    MultiEmbedImageIn: {
      /** @description Items to embed. */
      items: {
        /** @description Image to embed. */
        image_uri: string;
        /** @description Vector store document ID. Ignored if `collection_name` is unset. */
        doc_id?: string;
      }[];
      /** @description Vector store name. */
      collection_name?: string;
      /**
       * @description Selected embedding model.
       * @default clip
       * @enum {string}
       */
      model?: "clip";
    };
    /** MultiEmbedImageOut */
    MultiEmbedImageOut: {
      /** @description Generated embeddings. */
      embeddings: {
        /** @description Embedding vector. */
        vector: number[];
        /** @description Vector store document ID. */
        doc_id?: string;
        /** @description Vector store document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** CLIPIn */
    CLIPIn: {
      /** @description Items to embed. */
      items: {
        /** @description Image to embed. */
        image_uri?: string;
        /** @description Text to embed. */
        text?: string;
        /** @description Metadata that can be used to query the vector store. Ignored if `collection_name` is unset. */
        metadata?: {
          [key: string]: unknown;
        };
        /** @description Vector store document ID. Ignored if `collection_name` is unset. */
        doc_id?: string;
      }[];
      /** @description Vector store name. */
      collection_name?: string;
      /** @description Choose keys from `metadata` to embed with text. Only applies to text items. */
      embedded_metadata_keys?: string[];
    };
    /** CLIPOut */
    CLIPOut: {
      /** @description Generated embeddings. */
      embeddings: {
        /** @description Embedding vector. */
        vector: number[];
        /** @description Vector store document ID. */
        doc_id?: string;
        /** @description Vector store document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** FindOrCreateVectorStoreIn */
    FindOrCreateVectorStoreIn: {
      /** @description Vector store name. */
      collection_name: string;
      /**
       * @description Selected embedding model.
       * @enum {string}
       */
      model: "jina-v2" | "clip";
    };
    /** FindOrCreateVectorStoreOut */
    FindOrCreateVectorStoreOut: {
      /** @description Vector store name. */
      collection_name: string;
      /**
       * @description Selected embedding model.
       * @enum {string}
       */
      model: "jina-v2" | "clip";
    };
    /** ListVectorStoresIn */
    ListVectorStoresIn: Record<string, never>;
    /** ListVectorStoresOut */
    ListVectorStoresOut: {
      /** @description List of vector stores. */
      items?: {
        /** @description Vector store name. */
        collection_name: string;
        /**
         * @description Selected embedding model.
         * @enum {string}
         */
        model: "jina-v2" | "clip";
      }[];
    };
    /** DeleteVectorStoreIn */
    DeleteVectorStoreIn: {
      /** @description Vector store name. */
      collection_name: string;
      /**
       * @description Selected embedding model.
       * @enum {string}
       */
      model: "jina-v2" | "clip";
    };
    /** DeleteVectorStoreOut */
    DeleteVectorStoreOut: {
      /** @description Vector store name. */
      collection_name: string;
      /**
       * @description Selected embedding model.
       * @enum {string}
       */
      model: "jina-v2" | "clip";
    };
    /**
     * Vector
     * @description Canonical representation of document with embedding vector.
     */
    Vector: {
      /** @description Document ID. */
      id: string;
      /** @description Embedding vector. */
      vector: number[];
      /** @description Document metadata. */
      metadata: {
        [key: string]: unknown;
      };
    };
    /** FetchVectorsIn */
    FetchVectorsIn: {
      /** @description Vector store name. */
      collection_name: string;
      /**
       * @description Selected embedding model.
       * @enum {string}
       */
      model: "jina-v2" | "clip";
      /** @description Document IDs to retrieve. */
      ids: string[];
    };
    /** FetchVectorsOut */
    FetchVectorsOut: {
      /** @description Retrieved vectors. */
      vectors: {
        /** @description Document ID. */
        id: string;
        /** @description Embedding vector. */
        vector: number[];
        /** @description Document metadata. */
        metadata: {
          [key: string]: unknown;
        };
      }[];
    };
    /** UpdateVectorsOut */
    UpdateVectorsOut: {
      /** @description Number of vectors modified. */
      count: number;
    };
    /** DeleteVectorsOut */
    DeleteVectorsOut: {
      /** @description Number of vectors modified. */
      count: number;
    };
    /** UpdateVectorParams */
    UpdateVectorParams: {
      /** @description Document ID. */
      id: string;
      /** @description Embedding vector. */
      vector?: number[];
      /** @description Document metadata. */
      metadata?: {
        [key: string]: unknown;
      };
    };
    /** UpdateVectorsIn */
    UpdateVectorsIn: {
      /** @description Vector store name. */
      collection_name: string;
      /**
       * @description Selected embedding model.
       * @enum {string}
       */
      model: "jina-v2" | "clip";
      /** @description Vectors to upsert. */
      vectors: {
        /** @description Document ID. */
        id: string;
        /** @description Embedding vector. */
        vector?: number[];
        /** @description Document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** DeleteVectorsIn */
    DeleteVectorsIn: {
      /** @description Vector store name. */
      collection_name: string;
      /**
       * @description Selected embedding model.
       * @enum {string}
       */
      model: "jina-v2" | "clip";
      /** @description Document IDs to delete. */
      ids: string[];
    };
    /** QueryVectorStoreIn */
    QueryVectorStoreIn: {
      /** @description Vector store to query against. */
      collection_name: string;
      /**
       * @description Selected embedding model.
       * @enum {string}
       */
      model: "jina-v2" | "clip";
      /** @description Texts to embed and use for the query. */
      query_strings?: string[];
      /** @description Image URIs to embed and use for the query. */
      query_image_uris?: string[];
      /** @description Vectors to use for the query. */
      query_vectors?: number[][];
      /** @description Document IDs to use for the query. */
      query_ids?: string[];
      /**
       * @description Number of results to return.
       * @default 10
       */
      top_k?: number;
      /**
       * @description The size of the dynamic candidate list for searching the index graph.
       * @default 40
       */
      ef_search?: number;
      /**
       * @description Include the values of the vectors in the response.
       * @default false
       */
      include_values?: boolean;
      /**
       * @description Include the metadata of the vectors in the response.
       * @default false
       */
      include_metadata?: boolean;
      /** @description Filter metadata by key-value pairs. */
      filters?: {
        [key: string]: unknown;
      };
    };
    /** VectorStoreQueryResult */
    VectorStoreQueryResult: {
      /** @description Document ID. */
      id: string;
      /**
       * Format: float
       * @description Similarity score.
       */
      distance: number;
      /** @description Embedding vector. */
      vector?: number[];
      /** @description Document metadata. */
      metadata?: {
        [key: string]: unknown;
      };
    };
    /** QueryVectorStoreOut */
    QueryVectorStoreOut: {
      /** @description Query results. */
      results: {
        /** @description Document ID. */
        id: string;
        /**
         * Format: float
         * @description Similarity score.
         */
        distance: number;
        /** @description Embedding vector. */
        vector?: number[];
        /** @description Document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      }[][];
      /** @description Vector store name. */
      collection_name?: string;
      /**
       * @description Selected embedding model.
       * @enum {string}
       */
      model?: "jina-v2" | "clip";
    };
  };
  responses: never;
  parameters: never;
  requestBodies: never;
  headers: never;
  pathItems: never;
}

export type $defs = Record<string, never>;

export type external = Record<string, never>;

export interface operations {
  /**
   * Experimental
   * @description Experimental node.
   */
  Experimental: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "name": "some_name",
         *   "args": {
         *     "foo": "bar"
         *   }
         * }
         */
        "application/json": {
          /** @description Identifier. */
          name: string;
          /** @description Arguments. */
          args: {
            [key: string]: unknown;
          };
          /**
           * @description Timeout in seconds.
           * @default 60
           */
          timeout?: number;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Response. */
            output: {
              [key: string]: unknown;
            };
          };
        };
      };
    };
  };
  /**
   * RunPython
   * @description Run code using a Python interpreter.
   */
  RunPython: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "pkl_function": "g2UjA5fX2t3ZGVmYXVsdHNfX5ROjAxfX2RlZmF1bHRzX1+UTowKX19tb2R1bGVfX5SMCF9fbWFpbl9flIwHX19kb2NfX5ROjAtfX2Nsb3N1cmVfX5ROjBdfY2xvdWRwaWNrbGVfc3VibW9kdWxlc5RdlIwLX19nbG9iYWxzX1+UfZR1hpSGUjAu",
         *   "kwargs": {},
         *   "pip_install": [
         *     "numpy"
         *   ]
         * }
         */
        "application/json": {
          /** @description Pickled function. */
          pkl_function?: string;
          /** @description Keyword arguments to your function. */
          kwargs: {
            [key: string]: unknown;
          };
          /** @description Python version. */
          python_version?: string;
          /** @description Python packages to install. You must import them in your code. */
          pip_install?: string[];
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Return value of your function. */
            output?: unknown;
            /** @description Pickled return value. */
            pkl_output?: string;
            /** @description Everything printed to stdout while running your code. */
            stdout: string;
            /** @description Contents of stderr if your code did not run successfully. */
            stderr: string;
          };
        };
      };
    };
  };
  /**
   * GenerateText
   * @description Generate text using a language model.
   */
  GenerateText: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompt": "Who is Don Quixote?",
         *   "temperature": 0.4,
         *   "max_tokens": 800
         * }
         */
        "application/json": {
          /** @description Input prompt. */
          prompt: string;
          /** @description Image prompts. */
          image_uris?: string[];
          /**
           * Format: float
           * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
           * @default 0.4
           */
          temperature?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
          /**
           * @description Selected model. `Firellava13B` is automatically selected when `image_uris` is provided.
           * @default Llama3Instruct8B
           * @enum {string}
           */
          model?:
            | "Mistral7BInstruct"
            | "Mixtral8x7BInstruct"
            | "Llama3Instruct8B"
            | "Llama3Instruct70B"
            | "Firellava13B";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Text response. */
            text: string;
          };
        };
      };
    };
  };
  /**
   * MultiGenerateText
   * @description Generate multiple text choices using a language model.
   */
  MultiGenerateText: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompt": "Who is Don Quixote?",
         *   "num_choices": 2,
         *   "max_tokens": 800
         * }
         */
        "application/json": {
          /** @description Input prompt. */
          prompt: string;
          /**
           * @description Number of choices to generate.
           * @default 1
           */
          num_choices: number;
          /**
           * Format: float
           * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
           * @default 0.4
           */
          temperature?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
          /**
           * @description Selected model.
           * @default Llama3Instruct8B
           * @enum {string}
           */
          model?:
            | "Mistral7BInstruct"
            | "Mixtral8x7BInstruct"
            | "Llama3Instruct8B"
            | "Llama3Instruct70B";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Response choices. */
            choices: {
              /** @description Text response. */
              text: string;
            }[];
          };
        };
      };
    };
  };
  /**
   * BatchGenerateText
   * @description Generate text for multiple prompts in batch using a language model.
   */
  BatchGenerateText: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompts": [
         *     "Who is Don Quixote?",
         *     "Who is Sancho Panza?"
         *   ],
         *   "max_tokens": 800
         * }
         */
        "application/json": {
          /** @description Batch input prompts. */
          prompts: string[];
          /**
           * Format: float
           * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
           * @default 0.4
           */
          temperature?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
          /**
           * @description Selected model.
           * @default Llama3Instruct8B
           * @enum {string}
           */
          model?: "Mistral7BInstruct" | "Llama3Instruct8B";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Batch outputs. */
            outputs: {
              /** @description Text response. */
              text: string;
            }[];
          };
        };
      };
    };
  };
  /**
   * BatchGenerateJSON
   * @description Generate JSON for multiple prompts in batch using a language model.
   */
  BatchGenerateJSON: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompts": [
         *     "Who is Don Quixote?",
         *     "Who is Sancho Panza?"
         *   ],
         *   "max_tokens": 800,
         *   "json_schema": {
         *     "type": "object",
         *     "properties": {
         *       "name": {
         *         "type": "string",
         *         "description": "The name of the character."
         *       },
         *       "bio": {
         *         "type": "string",
         *         "description": "Concise biography of the character."
         *       }
         *     }
         *   }
         * }
         */
        "application/json": {
          /** @description Batch input prompts. */
          prompts: string[];
          /** @description JSON schema to guide `json_object` response. */
          json_schema: {
            [key: string]: unknown;
          };
          /**
           * Format: float
           * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
           * @default 0.4
           */
          temperature?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
          /**
           * @description Selected model.
           * @default Llama3Instruct8B
           * @enum {string}
           */
          model?: "Mistral7BInstruct" | "Llama3Instruct8B";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Batch outputs. */
            outputs: {
              /** @description JSON response. */
              json_object?: {
                [key: string]: unknown;
              };
              /** @description If the model output could not be parsed to JSON, this is the raw text output. */
              text?: string;
            }[];
          };
        };
      };
    };
  };
  /**
   * GenerateJSON
   * @description Generate JSON using a language model.
   */
  GenerateJSON: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompt": "Who wrote Don Quixote?",
         *   "json_schema": {
         *     "type": "object",
         *     "properties": {
         *       "name": {
         *         "type": "string",
         *         "description": "The name of the author."
         *       },
         *       "bio": {
         *         "type": "string",
         *         "description": "Concise biography of the author."
         *       }
         *     }
         *   },
         *   "temperature": 0.4,
         *   "max_tokens": 800
         * }
         */
        "application/json": {
          /** @description Input prompt. */
          prompt: string;
          /** @description JSON schema to guide `json_object` response. */
          json_schema: {
            [key: string]: unknown;
          };
          /**
           * Format: float
           * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
           * @default 0.4
           */
          temperature?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
          /**
           * @description Selected model.
           * @default Llama3Instruct8B
           * @enum {string}
           */
          model?:
            | "Mistral7BInstruct"
            | "Mixtral8x7BInstruct"
            | "Llama3Instruct8B";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description JSON response. */
            json_object?: {
              [key: string]: unknown;
            };
            /** @description If the model output could not be parsed to JSON, this is the raw text output. */
            text?: string;
          };
        };
      };
    };
  };
  /**
   * MultiGenerateJSON
   * @description Generate multiple JSON choices using a language model.
   */
  MultiGenerateJSON: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompt": "Who wrote Don Quixote?",
         *   "json_schema": {
         *     "type": "object",
         *     "properties": {
         *       "name": {
         *         "type": "string",
         *         "description": "The name of the author."
         *       },
         *       "bio": {
         *         "type": "string",
         *         "description": "Concise biography of the author."
         *       }
         *     }
         *   },
         *   "num_choices": 2,
         *   "temperature": 0.4,
         *   "max_tokens": 800
         * }
         */
        "application/json": {
          /** @description Input prompt. */
          prompt: string;
          /** @description JSON schema to guide `json_object` response. */
          json_schema: {
            [key: string]: unknown;
          };
          /**
           * @description Number of choices to generate.
           * @default 2
           */
          num_choices: number;
          /**
           * Format: float
           * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
           * @default 0.4
           */
          temperature?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
          /**
           * @description Selected model.
           * @default Llama3Instruct8B
           * @enum {string}
           */
          model?:
            | "Mistral7BInstruct"
            | "Mixtral8x7BInstruct"
            | "Llama3Instruct8B";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Response choices. */
            choices: {
              /** @description JSON response. */
              json_object?: {
                [key: string]: unknown;
              };
              /** @description If the model output could not be parsed to JSON, this is the raw text output. */
              text?: string;
            }[];
          };
        };
      };
    };
  };
  /**
   * Mistral7BInstruct
   * @description Generate text using [Mistral 7B Instruct](https://mistral.ai/news/announcing-mistral-7b).
   */
  Mistral7BInstruct: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompt": "Who is Don Quixote?",
         *   "num_choices": 2,
         *   "temperature": 0.4,
         *   "max_tokens": 800
         * }
         */
        "application/json": {
          /** @description Input prompt. */
          prompt: string;
          /** @description System prompt. */
          system_prompt?: string;
          /**
           * @description Number of choices to generate.
           * @default 1
           */
          num_choices?: number;
          /** @description JSON schema to guide response. */
          json_schema?: {
            [key: string]: unknown;
          };
          /**
           * Format: float
           * @description Higher values make the output more random, lower values make the output more deterministic.
           */
          temperature?: number;
          /**
           * Format: float
           * @description Higher values decrease the likelihood of repeating previous tokens.
           * @default 0
           */
          frequency_penalty?: number;
          /**
           * Format: float
           * @description Higher values decrease the likelihood of repeated sequences.
           * @default 1
           */
          repetition_penalty?: number;
          /**
           * Format: float
           * @description Higher values increase the likelihood of new topics appearing.
           * @default 1.1
           */
          presence_penalty?: number;
          /**
           * Format: float
           * @description Probability below which less likely tokens are filtered out.
           * @default 0.95
           */
          top_p?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Response choices. */
            choices: {
              /** @description Text response, if `json_schema` was not provided. */
              text?: string;
              /** @description JSON response, if `json_schema` was provided. */
              json_object?: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * Mixtral8x7BInstruct
   * @description Generate text using instruct-tuned [Mixtral 8x7B](https://mistral.ai/news/mixtral-of-experts/).
   */
  Mixtral8x7BInstruct: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompt": "Who is Don Quixote?",
         *   "num_choices": 2,
         *   "temperature": 0.4,
         *   "max_tokens": 800
         * }
         */
        "application/json": {
          /** @description Input prompt. */
          prompt: string;
          /** @description System prompt. */
          system_prompt?: string;
          /**
           * @description Number of choices to generate.
           * @default 1
           */
          num_choices?: number;
          /** @description JSON schema to guide response. */
          json_schema?: {
            [key: string]: unknown;
          };
          /**
           * Format: float
           * @description Higher values make the output more random, lower values make the output more deterministic.
           */
          temperature?: number;
          /**
           * Format: float
           * @description Higher values decrease the likelihood of repeating previous tokens.
           * @default 0
           */
          frequency_penalty?: number;
          /**
           * Format: float
           * @description Higher values decrease the likelihood of repeated sequences.
           * @default 1
           */
          repetition_penalty?: number;
          /**
           * Format: float
           * @description Higher values increase the likelihood of new topics appearing.
           * @default 1.1
           */
          presence_penalty?: number;
          /**
           * Format: float
           * @description Probability below which less likely tokens are filtered out.
           * @default 0.95
           */
          top_p?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Response choices. */
            choices: {
              /** @description Text response, if `json_schema` was not provided. */
              text?: string;
              /** @description JSON response, if `json_schema` was provided. */
              json_object?: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * Llama3Instruct8B
   * @description Generate text using instruct-tuned [Llama 3 8B](https://llama.meta.com/llama3/).
   */
  Llama3Instruct8B: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompt": "Who is Don Quixote?",
         *   "num_choices": 2,
         *   "temperature": 0.4,
         *   "max_tokens": 800
         * }
         */
        "application/json": {
          /** @description Input prompt. */
          prompt: string;
          /** @description System prompt. */
          system_prompt?: string;
          /**
           * @description Number of choices to generate.
           * @default 1
           */
          num_choices?: number;
          /**
           * Format: float
           * @description Higher values make the output more random, lower values make the output more deterministic.
           */
          temperature?: number;
          /**
           * Format: float
           * @description Higher values decrease the likelihood of repeating previous tokens.
           * @default 0
           */
          frequency_penalty?: number;
          /**
           * Format: float
           * @description Higher values decrease the likelihood of repeated sequences.
           * @default 1
           */
          repetition_penalty?: number;
          /**
           * Format: float
           * @description Higher values increase the likelihood of new topics appearing.
           * @default 1.1
           */
          presence_penalty?: number;
          /**
           * Format: float
           * @description Probability below which less likely tokens are filtered out.
           * @default 0.95
           */
          top_p?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
          /** @description JSON schema to guide response. */
          json_schema?: {
            [key: string]: unknown;
          };
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Response choices. */
            choices: {
              /** @description Text response. */
              text?: string;
              /** @description JSON response, if `json_schema` was provided. */
              json_object?: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * Llama3Instruct70B
   * @description Generate text using instruct-tuned [Llama 3 70B](https://llama.meta.com/llama3/).
   */
  Llama3Instruct70B: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompt": "Who is Don Quixote?",
         *   "num_choices": 2,
         *   "temperature": 0.4,
         *   "max_tokens": 800
         * }
         */
        "application/json": {
          /** @description Input prompt. */
          prompt: string;
          /** @description System prompt. */
          system_prompt?: string;
          /**
           * @description Number of choices to generate.
           * @default 1
           */
          num_choices?: number;
          /**
           * Format: float
           * @description Higher values make the output more random, lower values make the output more deterministic.
           */
          temperature?: number;
          /**
           * Format: float
           * @description Higher values decrease the likelihood of repeating previous tokens.
           * @default 0
           */
          frequency_penalty?: number;
          /**
           * Format: float
           * @description Higher values decrease the likelihood of repeated sequences.
           * @default 1
           */
          repetition_penalty?: number;
          /**
           * Format: float
           * @description Higher values increase the likelihood of new topics appearing.
           * @default 1.1
           */
          presence_penalty?: number;
          /**
           * Format: float
           * @description Probability below which less likely tokens are filtered out.
           * @default 0.95
           */
          top_p?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Response choices. */
            choices: {
              /** @description Text response. */
              text?: string;
            }[];
          };
        };
      };
    };
  };
  /**
   * Firellava13B
   * @description Generate text with image input using [FireLLaVA 13B](https://fireworks.ai/blog/firellava-the-first-commercially-permissive-oss-llava-model).
   */
  Firellava13B: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompt": "what are these paintings of and who made them?",
         *   "image_uris": [
         *     "https://media.substrate.run/docs-fuji-red.jpg",
         *     "https://media.substrate.run/docs-fuji-blue.jpg"
         *   ]
         * }
         */
        "application/json": {
          /** @description Text prompt. */
          prompt: string;
          /** @description Image prompts. */
          image_uris: string[];
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Text response. */
            text: string;
          };
        };
      };
    };
  };
  /**
   * GenerateImage
   * @description Generate an image.
   */
  GenerateImage: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompt": "hokusai futuristic supercell spiral cloud with glowing core over turbulent ocean",
         *   "store": "hosted"
         * }
         */
        "application/json": {
          /** @description Text prompt. */
          prompt: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            image_uri: string;
          };
        };
      };
    };
  };
  /**
   * MultiGenerateImage
   * @description Generate multiple images.
   */
  MultiGenerateImage: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompt": "hokusai futuristic supercell spiral cloud with glowing core over turbulent ocean",
         *   "num_images": 2,
         *   "store": "hosted"
         * }
         */
        "application/json": {
          /** @description Text prompt. */
          prompt: string;
          /**
           * @description Number of images to generate.
           * @default 2
           */
          num_images: number;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Generated images. */
            outputs: {
              /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
              image_uri: string;
            }[];
          };
        };
      };
    };
  };
  /**
   * InpaintImage
   * @description Edit an image using image generation inside part of the image or the full image.
   */
  InpaintImage: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "image_uri": "https://media.substrate.run/docs-klimt-park.jpg",
         *   "mask_image_uri": "https://media.substrate.run/spiral-logo.jpeg",
         *   "prompt": "large tropical colorful bright anime birds in a dark jungle full of vines, high resolution",
         *   "store": "hosted"
         * }
         */
        "application/json": {
          /** @description Original image. */
          image_uri: string;
          /** @description Text prompt. */
          prompt: string;
          /** @description Mask image that controls which pixels are inpainted. If unset, the entire image is edited (image-to-image). */
          mask_image_uri?: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            image_uri: string;
          };
        };
      };
    };
  };
  /**
   * MultiInpaintImage
   * @description Edit multiple images using image generation.
   */
  MultiInpaintImage: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "image_uri": "https://media.substrate.run/docs-klimt-park.jpg",
         *   "mask_image_uri": "https://media.substrate.run/spiral-logo.jpeg",
         *   "prompt": "large tropical colorful bright anime birds in a dark jungle full of vines, high resolution",
         *   "num_images": 2,
         *   "store": "hosted"
         * }
         */
        "application/json": {
          /** @description Original image. */
          image_uri: string;
          /** @description Text prompt. */
          prompt: string;
          /** @description Mask image that controls which pixels are edited (inpainting). If unset, the entire image is edited (image-to-image). */
          mask_image_uri?: string;
          /**
           * @description Number of images to generate.
           * @default 2
           */
          num_images: number;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Generated images. */
            outputs: {
              /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
              image_uri: string;
            }[];
          };
        };
      };
    };
  };
  /**
   * StableDiffusionXLLightning
   * @description Generate an image using [Stable Diffusion XL Lightning](https://arxiv.org/abs/2402.13929).
   */
  StableDiffusionXLLightning: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompt": "hokusai futuristic supercell spiral cloud with glowing core over turbulent ocean",
         *   "negative_prompt": "night, moon",
         *   "num_images": 2,
         *   "seeds": [
         *     3306990332671669000,
         *     13641924104177017000
         *   ],
         *   "store": "hosted"
         * }
         */
        "application/json": {
          /** @description Text prompt. */
          prompt: string;
          /** @description Negative input prompt. */
          negative_prompt?: string;
          /**
           * @description Number of images to generate.
           * @default 1
           */
          num_images?: number;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * @description Height of output image, in pixels.
           * @default 1024
           */
          height?: number;
          /**
           * @description Width of output image, in pixels.
           * @default 1024
           */
          width?: number;
          /** @description Seeds for deterministic generation. Default is a random seed. */
          seeds?: number[];
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Generated images. */
            outputs: {
              /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
              image_uri: string;
              /** @description The random noise seed used for generation. */
              seed: number;
            }[];
          };
        };
      };
    };
  };
  /**
   * StableDiffusionXLInpaint
   * @description Edit an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952). Supports inpainting (edit part of the image with a mask) and image-to-image (edit the full image).
   */
  StableDiffusionXLInpaint: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "image_uri": "https://media.substrate.run/docs-klimt-park.jpg",
         *   "mask_image_uri": "https://media.substrate.run/spiral-logo.jpeg",
         *   "prompt": "large tropical colorful bright birds in a jungle, high resolution oil painting",
         *   "negative_prompt": "dark, cartoon, anime",
         *   "strength": 0.8,
         *   "num_images": 2,
         *   "store": "hosted",
         *   "seeds": [
         *     16072680593433106000,
         *     17203982922585030000
         *   ]
         * }
         */
        "application/json": {
          /** @description Original image. */
          image_uri: string;
          /** @description Text prompt. */
          prompt: string;
          /** @description Mask image that controls which pixels are edited (inpainting). If unset, the entire image is edited (image-to-image). */
          mask_image_uri?: string;
          /**
           * @description Number of images to generate.
           * @default 1
           */
          num_images: number;
          /**
           * @description Resolution of the output image, in pixels.
           * @default 1024
           */
          output_resolution?: number;
          /** @description Negative input prompt. */
          negative_prompt?: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * Format: float
           * @description Controls the strength of the generation process.
           * @default 0.8
           */
          strength?: number;
          /** @description Random noise seeds. Default is random seeds for each generation. */
          seeds?: number[];
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Generated images. */
            outputs: {
              /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
              image_uri: string;
              /** @description The random noise seed used for generation. */
              seed: number;
            }[];
          };
        };
      };
    };
  };
  /**
   * StableDiffusionXLControlNet
   * @description Generate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543).
   */
  StableDiffusionXLControlNet: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "image_uri": "https://media.substrate.run/spiral-logo.jpeg",
         *   "prompt": "the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD",
         *   "control_method": "illusion",
         *   "conditioning_scale": 1,
         *   "strength": 1,
         *   "store": "hosted",
         *   "num_images": 2,
         *   "seeds": [
         *     16072680593433106000,
         *     17203982922585030000
         *   ]
         * }
         */
        "application/json": {
          /** @description Input image. */
          image_uri: string;
          /**
           * @description Strategy to control generation using the input image.
           * @enum {string}
           */
          control_method: "edge" | "depth" | "illusion" | "tile";
          /** @description Text prompt. */
          prompt: string;
          /**
           * @description Number of images to generate.
           * @default 1
           */
          num_images: number;
          /**
           * @description Resolution of the output image, in pixels.
           * @default 1024
           */
          output_resolution?: number;
          /** @description Negative input prompt. */
          negative_prompt?: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * Format: float
           * @description Controls the influence of the input image on the generated output.
           * @default 0.5
           */
          conditioning_scale?: number;
          /**
           * Format: float
           * @description Controls how much to transform the input image.
           * @default 0.5
           */
          strength?: number;
          /** @description Random noise seeds. Default is random seeds for each generation. */
          seeds?: number[];
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Generated images. */
            outputs: {
              /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
              image_uri: string;
              /** @description The random noise seed used for generation. */
              seed: number;
            }[];
          };
        };
      };
    };
  };
  /**
   * TranscribeSpeech
   * @description Transcribe speech in an audio or video file.
   */
  TranscribeSpeech: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "audio_uri": "https://media.substrate.run/dfw-clip.m4a",
         *   "prompt": "David Foster Wallace interviewed about US culture, and Infinite Jest",
         *   "segment": true,
         *   "align": true,
         *   "diarize": true,
         *   "suggest_chapters": true
         * }
         */
        "application/json": {
          /** @description Input audio. */
          audio_uri: string;
          /** @description Prompt to guide model on the content and context of input audio. */
          prompt?: string;
          /**
           * @description Language of input audio in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes) format.
           * @default en
           */
          language?: string;
          /**
           * @description Segment the text into sentences with approximate timestamps.
           * @default false
           */
          segment?: boolean;
          /**
           * @description Align transcription to produce more accurate sentence-level timestamps and word-level timestamps. An array of word segments will be included in each sentence segment.
           * @default false
           */
          align?: boolean;
          /**
           * @description Identify speakers for each segment. Speaker IDs will be included in each segment.
           * @default false
           */
          diarize?: boolean;
          /**
           * @description Suggest automatic chapter markers.
           * @default false
           */
          suggest_chapters?: boolean;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Transcribed text. */
            text: string;
            /** @description Transcribed segments, if `segment` is enabled. */
            segments?: {
              /** @description Text of segment. */
              text: string;
              /**
               * Format: float
               * @description Start time of segment, in seconds.
               */
              start: number;
              /**
               * Format: float
               * @description End time of segment, in seconds.
               */
              end: number;
              /** @description ID of speaker, if `diarize` is enabled. */
              speaker?: string;
              /** @description Aligned words, if `align` is enabled. */
              words?: {
                /** @description Text of word. */
                word: string;
                /**
                 * Format: float
                 * @description Start time of word, in seconds.
                 */
                start?: number;
                /**
                 * Format: float
                 * @description End time of word, in seconds.
                 */
                end?: number;
                /** @description ID of speaker, if `diarize` is enabled. */
                speaker?: string;
              }[];
            }[];
            /** @description Chapter markers, if `suggest_chapters` is enabled. */
            chapters?: {
              /** @description Chapter title. */
              title: string;
              /**
               * Format: float
               * @description Start time of chapter, in seconds.
               */
              start: number;
            }[];
          };
        };
      };
    };
  };
  /**
   * GenerateSpeech
   * @description Generate speech from text.
   */
  GenerateSpeech: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "text": "Substrate: an underlying substance or layer.",
         *   "store": "hosted"
         * }
         */
        "application/json": {
          /** @description Input text. */
          text: string;
          /** @description Use "hosted" to return an audio URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the audio data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded WAV audio bytes, or a hosted audio url if `store` is provided. */
            audio_uri: string;
          };
        };
      };
    };
  };
  /**
   * RemoveBackground
   * @description Remove the background from an image and return the foreground segment as a cut-out or a mask.
   */
  RemoveBackground: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "image_uri": "https://media.substrate.run/apple-forest.jpeg",
         *   "store": "hosted"
         * }
         */
        "application/json": {
          /** @description Input image. */
          image_uri: string;
          /**
           * @description Return a mask image instead of the original content.
           * @default false
           */
          return_mask?: boolean;
          /** @description Hex value background color. Transparent if unset. */
          background_color?: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            image_uri: string;
          };
        };
      };
    };
  };
  /**
   * EraseImage
   * @description Erase the masked part of an image, e.g. to 'remove' an object.
   */
  EraseImage: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "image_uri": "https://media.substrate.run/apple-forest.jpeg",
         *   "mask_image_uri": "https://media.substrate.run/apple-forest-mask.jpeg",
         *   "store": "hosted"
         * }
         */
        "application/json": {
          /** @description Input image. */
          image_uri: string;
          /** @description Mask image that controls which pixels are inpainted. */
          mask_image_uri: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            image_uri: string;
          };
        };
      };
    };
  };
  /**
   * UpscaleImage
   * @description Upscale an image using image generation.
   */
  UpscaleImage: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "prompt": "high resolution detailed spiral shell",
         *   "image_uri": "https://media.substrate.run/docs-shell-emoji.jpg",
         *   "store": "hosted"
         * }
         */
        "application/json": {
          /** @description Prompt to guide model on the content of image to upscale. */
          prompt?: string;
          /** @description Input image. */
          image_uri: string;
          /**
           * @description Resolution of the output image, in pixels.
           * @default 1024
           */
          output_resolution?: number;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            image_uri: string;
          };
        };
      };
    };
  };
  /**
   * SegmentUnderPoint
   * @description Segment an image under a point and return the segment.
   */
  SegmentUnderPoint: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "image_uri": "https://media.substrate.run/docs-vg-bedroom.jpg",
         *   "point": {
         *     "x": 189,
         *     "y": 537
         *   },
         *   "store": "hosted"
         * }
         */
        "application/json": {
          /** @description Input image. */
          image_uri: string;
          /** Point */
          point: {
            /** @description X position. */
            x: number;
            /** @description Y position. */
            y: number;
          };
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Detected segments in 'mask image' format. Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            mask_image_uri: string;
          };
        };
      };
    };
  };
  /**
   * SegmentAnything
   * @description Segment an image using [SegmentAnything](https://github.com/facebookresearch/segment-anything).
   */
  SegmentAnything: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "image_uri": "https://media.substrate.run/docs-vg-bedroom.jpg",
         *   "point_prompts": [
         *     {
         *       "x": 189,
         *       "y": 537
         *     }
         *   ],
         *   "store": "hosted"
         * }
         */
        "application/json": {
          /** @description Input image. */
          image_uri: string;
          /** @description Point prompts, to detect a segment under the point. One of `point_prompts` or `box_prompts` must be set. */
          point_prompts?: {
            /** @description X position. */
            x: number;
            /** @description Y position. */
            y: number;
          }[];
          /** @description Box prompts, to detect a segment within the bounding box. One of `point_prompts` or `box_prompts` must be set. */
          box_prompts?: {
            /**
             * Format: float
             * @description Top left corner x.
             */
            x1: number;
            /**
             * Format: float
             * @description Top left corner y.
             */
            y1: number;
            /**
             * Format: float
             * @description Bottom right corner x.
             */
            x2: number;
            /**
             * Format: float
             * @description Bottom right corner y.
             */
            y2: number;
          }[];
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](https://guides.substrate.run/guides/external-file-storage). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Detected segments in 'mask image' format. Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            mask_image_uri: string;
          };
        };
      };
    };
  };
  /**
   * EmbedText
   * @description Generate embedding for a text document.
   */
  EmbedText: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "text": "Argon is the third most abundant gas in Earth's atmosphere, at 0.934% (9340 ppmv). It is more than twice as abundant as water vapor.",
         *   "model": "jina-v2",
         *   "collection_name": "smoke_tests",
         *   "metadata": {
         *     "group": "18"
         *   },
         *   "embedded_metadata_keys": [
         *     "group"
         *   ]
         * }
         */
        "application/json": {
          /** @description Text to embed. */
          text: string;
          /** @description Vector store name. */
          collection_name?: string;
          /** @description Metadata that can be used to query the vector store. Ignored if `collection_name` is unset. */
          metadata?: {
            [key: string]: unknown;
          };
          /** @description Choose keys from `metadata` to embed with text. */
          embedded_metadata_keys?: string[];
          /** @description Vector store document ID. Ignored if `store` is unset. */
          doc_id?: string;
          /**
           * @description Selected embedding model.
           * @default jina-v2
           * @enum {string}
           */
          model?: "jina-v2" | "clip";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** Embedding */
            embedding: {
              /** @description Embedding vector. */
              vector: number[];
              /** @description Vector store document ID. */
              doc_id?: string;
              /** @description Vector store document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            };
          };
        };
      };
    };
  };
  /**
   * MultiEmbedText
   * @description Generate embeddings for multiple text documents.
   */
  MultiEmbedText: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "model": "jina-v2",
         *   "items": [
         *     {
         *       "text": "Osmium is the densest naturally occurring element. When experimentally measured using X-ray crystallography, it has a density of 22.59 g/cm3. Manufacturers use its alloys with platinum, iridium, and other platinum-group metals to make fountain pen nib tipping, electrical contacts, and in other applications that require extreme durability and hardness.",
         *       "metadata": {
         *         "group": "8"
         *       }
         *     },
         *     {
         *       "text": "Despite its abundant presence in the universe and Solar System—ranking fifth in cosmic abundance following hydrogen, helium, oxygen, and carbon—neon is comparatively scarce on Earth.",
         *       "metadata": {
         *         "group": "18"
         *       }
         *     }
         *   ],
         *   "collection_name": "smoke_tests",
         *   "embedded_metadata_keys": [
         *     "group"
         *   ]
         * }
         */
        "application/json": {
          /** @description Items to embed. */
          items: {
            /** @description Text to embed. */
            text: string;
            /** @description Metadata that can be used to query the vector store. Ignored if `collection_name` is unset. */
            metadata?: {
              [key: string]: unknown;
            };
            /** @description Vector store document ID. Ignored if `collection_name` is unset. */
            doc_id?: string;
          }[];
          /** @description Vector store name. */
          collection_name?: string;
          /** @description Choose keys from `metadata` to embed with text. */
          embedded_metadata_keys?: string[];
          /**
           * @description Selected embedding model.
           * @default jina-v2
           * @enum {string}
           */
          model?: "jina-v2" | "clip";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Generated embeddings. */
            embeddings: {
              /** @description Embedding vector. */
              vector: number[];
              /** @description Vector store document ID. */
              doc_id?: string;
              /** @description Vector store document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * EmbedImage
   * @description Generate embedding for an image.
   */
  EmbedImage: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "image_uri": "https://media.substrate.run/docs-fuji-red.jpg",
         *   "collection_name": "smoke_tests"
         * }
         */
        "application/json": {
          /** @description Image to embed. */
          image_uri: string;
          /** @description Vector store name. */
          collection_name?: string;
          /** @description Vector store document ID. Ignored if `collection_name` is unset. */
          doc_id?: string;
          /**
           * @description Selected embedding model.
           * @default clip
           * @enum {string}
           */
          model?: "clip";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** Embedding */
            embedding: {
              /** @description Embedding vector. */
              vector: number[];
              /** @description Vector store document ID. */
              doc_id?: string;
              /** @description Vector store document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            };
          };
        };
      };
    };
  };
  /**
   * MultiEmbedImage
   * @description Generate embeddings for multiple images.
   */
  MultiEmbedImage: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "items": [
         *     {
         *       "image_uri": "https://media.substrate.run/docs-fuji-red.jpg"
         *     },
         *     {
         *       "image_uri": "https://media.substrate.run/docs-fuji-blue.jpg"
         *     }
         *   ],
         *   "collection_name": "smoke_tests"
         * }
         */
        "application/json": {
          /** @description Items to embed. */
          items: {
            /** @description Image to embed. */
            image_uri: string;
            /** @description Vector store document ID. Ignored if `collection_name` is unset. */
            doc_id?: string;
          }[];
          /** @description Vector store name. */
          collection_name?: string;
          /**
           * @description Selected embedding model.
           * @default clip
           * @enum {string}
           */
          model?: "clip";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Generated embeddings. */
            embeddings: {
              /** @description Embedding vector. */
              vector: number[];
              /** @description Vector store document ID. */
              doc_id?: string;
              /** @description Vector store document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * JinaV2
   * @description Generate embeddings for multiple text documents using [Jina Embeddings 2](https://arxiv.org/abs/2310.19923).
   */
  JinaV2: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "items": [
         *     {
         *       "text": "Hassium is a superheavy element; it has been produced in a laboratory only in very small quantities by fusing heavy nuclei with lighter ones. Natural occurrences of the element have been hypothesised but never found.",
         *       "metadata": {
         *         "group": "8"
         *       }
         *     },
         *     {
         *       "text": "Xenon is also used to search for hypothetical weakly interacting massive particles and as a propellant for ion thrusters in spacecraft.",
         *       "metadata": {
         *         "group": "18"
         *       }
         *     }
         *   ],
         *   "collection_name": "smoke_tests",
         *   "embedded_metadata_keys": [
         *     "group"
         *   ]
         * }
         */
        "application/json": {
          /** @description Items to embed. */
          items: {
            /** @description Text to embed. */
            text: string;
            /** @description Metadata that can be used to query the vector store. Ignored if `collection_name` is unset. */
            metadata?: {
              [key: string]: unknown;
            };
            /** @description Vector store document ID. Ignored if `collection_name` is unset. */
            doc_id?: string;
          }[];
          /** @description Vector store name. */
          collection_name?: string;
          /** @description Choose keys from `metadata` to embed with text. */
          embedded_metadata_keys?: string[];
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Generated embeddings. */
            embeddings: {
              /** @description Embedding vector. */
              vector: number[];
              /** @description Vector store document ID. */
              doc_id?: string;
              /** @description Vector store document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * CLIP
   * @description Generate embeddings for text or images using [CLIP](https://openai.com/research/clip).
   */
  CLIP: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "items": [
         *     {
         *       "image_uri": "https://media.substrate.run/docs-fuji-red.jpg"
         *     },
         *     {
         *       "image_uri": "https://media.substrate.run/docs-fuji-blue.jpg"
         *     }
         *   ],
         *   "collection_name": "smoke_tests"
         * }
         */
        "application/json": {
          /** @description Items to embed. */
          items: {
            /** @description Image to embed. */
            image_uri?: string;
            /** @description Text to embed. */
            text?: string;
            /** @description Metadata that can be used to query the vector store. Ignored if `collection_name` is unset. */
            metadata?: {
              [key: string]: unknown;
            };
            /** @description Vector store document ID. Ignored if `collection_name` is unset. */
            doc_id?: string;
          }[];
          /** @description Vector store name. */
          collection_name?: string;
          /** @description Choose keys from `metadata` to embed with text. Only applies to text items. */
          embedded_metadata_keys?: string[];
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Generated embeddings. */
            embeddings: {
              /** @description Embedding vector. */
              vector: number[];
              /** @description Vector store document ID. */
              doc_id?: string;
              /** @description Vector store document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * FindOrCreateVectorStore
   * @description Find a vector store matching the given collection name, or create a new vector store.
   */
  FindOrCreateVectorStore: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "collection_name": "smoke_tests",
         *   "model": "jina-v2"
         * }
         */
        "application/json": {
          /** @description Vector store name. */
          collection_name: string;
          /**
           * @description Selected embedding model.
           * @enum {string}
           */
          model: "jina-v2" | "clip";
        };
      };
    };
    responses: {
      /** @description Vector store created. */
      200: {
        content: {
          "application/json": {
            /** @description Vector store name. */
            collection_name: string;
            /**
             * @description Selected embedding model.
             * @enum {string}
             */
            model: "jina-v2" | "clip";
          };
        };
      };
    };
  };
  /**
   * ListVectorStores
   * @description List all vector stores.
   */
  ListVectorStores: {
    requestBody?: {
      content: {
        /** @example {} */
        "application/json": Record<string, never>;
      };
    };
    responses: {
      /** @description List of vector stores. */
      200: {
        content: {
          "application/json": {
            /** @description List of vector stores. */
            items?: {
              /** @description Vector store name. */
              collection_name: string;
              /**
               * @description Selected embedding model.
               * @enum {string}
               */
              model: "jina-v2" | "clip";
            }[];
          };
        };
      };
    };
  };
  /**
   * DeleteVectorStore
   * @description Delete a vector store.
   */
  DeleteVectorStore: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "collection_name": "fake_store",
         *   "model": "jina-v2"
         * }
         */
        "application/json": {
          /** @description Vector store name. */
          collection_name: string;
          /**
           * @description Selected embedding model.
           * @enum {string}
           */
          model: "jina-v2" | "clip";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Vector store name. */
            collection_name: string;
            /**
             * @description Selected embedding model.
             * @enum {string}
             */
            model: "jina-v2" | "clip";
          };
        };
      };
    };
  };
  /**
   * QueryVectorStore
   * @description Query a vector store for similar vectors.
   */
  QueryVectorStore: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "collection_name": "smoke_tests",
         *   "model": "jina-v2",
         *   "query_strings": [
         *     "gas",
         *     "metal"
         *   ],
         *   "top_k": 1,
         *   "include_metadata": true
         * }
         */
        "application/json": {
          /** @description Vector store to query against. */
          collection_name: string;
          /**
           * @description Selected embedding model.
           * @enum {string}
           */
          model: "jina-v2" | "clip";
          /** @description Texts to embed and use for the query. */
          query_strings?: string[];
          /** @description Image URIs to embed and use for the query. */
          query_image_uris?: string[];
          /** @description Vectors to use for the query. */
          query_vectors?: number[][];
          /** @description Document IDs to use for the query. */
          query_ids?: string[];
          /**
           * @description Number of results to return.
           * @default 10
           */
          top_k?: number;
          /**
           * @description The size of the dynamic candidate list for searching the index graph.
           * @default 40
           */
          ef_search?: number;
          /**
           * @description Include the values of the vectors in the response.
           * @default false
           */
          include_values?: boolean;
          /**
           * @description Include the metadata of the vectors in the response.
           * @default false
           */
          include_metadata?: boolean;
          /** @description Filter metadata by key-value pairs. */
          filters?: {
            [key: string]: unknown;
          };
        };
      };
    };
    responses: {
      /** @description Query results. */
      200: {
        content: {
          "application/json": {
            /** @description Query results. */
            results: {
              /** @description Document ID. */
              id: string;
              /**
               * Format: float
               * @description Similarity score.
               */
              distance: number;
              /** @description Embedding vector. */
              vector?: number[];
              /** @description Document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            }[][];
            /** @description Vector store name. */
            collection_name?: string;
            /**
             * @description Selected embedding model.
             * @enum {string}
             */
            model?: "jina-v2" | "clip";
          };
        };
      };
    };
  };
  /**
   * FetchVectors
   * @description Fetch vectors from a vector store.
   */
  FetchVectors: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "collection_name": "smoke_tests",
         *   "model": "jina-v2",
         *   "ids": [
         *     "dd8f3774e05d42caa53cfbaa7389c08f"
         *   ]
         * }
         */
        "application/json": {
          /** @description Vector store name. */
          collection_name: string;
          /**
           * @description Selected embedding model.
           * @enum {string}
           */
          model: "jina-v2" | "clip";
          /** @description Document IDs to retrieve. */
          ids: string[];
        };
      };
    };
    responses: {
      /** @description Vector data. */
      200: {
        content: {
          "application/json": {
            /** @description Retrieved vectors. */
            vectors: {
              /** @description Document ID. */
              id: string;
              /** @description Embedding vector. */
              vector: number[];
              /** @description Document metadata. */
              metadata: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * UpdateVectors
   * @description Update vectors in a vector store.
   */
  UpdateVectors: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "collection_name": "smoke_tests",
         *   "model": "jina-v2",
         *   "vectors": [
         *     {
         *       "id": "dd8f3774e05d42caa53cfbaa7389c08f",
         *       "metadata": {
         *         "appearance": "silvery, blue cast"
         *       }
         *     }
         *   ]
         * }
         */
        "application/json": {
          /** @description Vector store name. */
          collection_name: string;
          /**
           * @description Selected embedding model.
           * @enum {string}
           */
          model: "jina-v2" | "clip";
          /** @description Vectors to upsert. */
          vectors: {
            /** @description Document ID. */
            id: string;
            /** @description Embedding vector. */
            vector?: number[];
            /** @description Document metadata. */
            metadata?: {
              [key: string]: unknown;
            };
          }[];
        };
      };
    };
    responses: {
      /** @description Count of updated vectors. */
      200: {
        content: {
          "application/json": {
            /** @description Number of vectors modified. */
            count: number;
          };
        };
      };
    };
  };
  /**
   * DeleteVectors
   * @description Delete vectors in a vector store.
   */
  DeleteVectors: {
    requestBody?: {
      content: {
        /**
         * @example {
         *   "collection_name": "smoke_tests",
         *   "model": "jina-v2",
         *   "ids": [
         *     "ac32b9a133dd4e3689004f6e8f0fd6cd",
         *     "629df177c7644062a68bceeff223cefa"
         *   ]
         * }
         */
        "application/json": {
          /** @description Vector store name. */
          collection_name: string;
          /**
           * @description Selected embedding model.
           * @enum {string}
           */
          model: "jina-v2" | "clip";
          /** @description Document IDs to delete. */
          ids: string[];
        };
      };
    };
    responses: {
      /** @description Count of deleted vectors. */
      200: {
        content: {
          "application/json": {
            /** @description Number of vectors modified. */
            count: number;
          };
        };
      };
    };
  };
}
