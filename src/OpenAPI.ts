/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */

export interface paths {
  "/GenerateText": {
    /**
     * GenerateText
     * @description Generate text using a language model.
     */
    post: operations["GenerateText"];
  };
  "/MultiGenerateText": {
    /**
     * MultiGenerateText
     * @description Generate multiple text choices using a language model.
     */
    post: operations["MultiGenerateText"];
  };
  "/GenerateJSON": {
    /**
     * GenerateJSON
     * @description Generate JSON using a language model.
     */
    post: operations["GenerateJSON"];
  };
  "/MultiGenerateJSON": {
    /**
     * MultiGenerateJSON
     * @description Generate multiple JSON choices using a language model.
     */
    post: operations["MultiGenerateJSON"];
  };
  "/GenerateTextVision": {
    /**
     * GenerateTextVision
     * @description Generate text with image input.
     */
    post: operations["GenerateTextVision"];
  };
  "/Mistral7BInstruct": {
    /**
     * Mistral7BInstruct
     * @description Generate text using [Mistral 7B Instruct](https://mistral.ai/news/announcing-mistral-7b).
     */
    post: operations["Mistral7BInstruct"];
  };
  "/Firellava13B": {
    /**
     * Firellava13B
     * @description Generate text with image input using [FireLLaVA 13B](https://fireworks.ai/blog/firellava-the-first-commercially-permissive-oss-llava-model).
     */
    post: operations["Firellava13B"];
  };
  "/GenerateImage": {
    /**
     * GenerateImage
     * @description Generate an image.
     */
    post: operations["GenerateImage"];
  };
  "/MultiGenerateImage": {
    /**
     * MultiGenerateImage
     * @description Generate multiple images.
     */
    post: operations["MultiGenerateImage"];
  };
  "/GenerativeEditImage": {
    /**
     * GenerativeEditImage
     * @description Edit an image using image generation.
     */
    post: operations["GenerativeEditImage"];
  };
  "/MultiGenerativeEditImage": {
    /**
     * MultiGenerativeEditImage
     * @description Edit multiple images using image generation.
     */
    post: operations["MultiGenerativeEditImage"];
  };
  "/StableDiffusionXL": {
    /**
     * StableDiffusionXL
     * @description Generate an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952).
     */
    post: operations["StableDiffusionXL"];
  };
  "/StableDiffusionXLLightning": {
    /**
     * StableDiffusionXLLightning
     * @description Generate an image using [Stable Diffusion XL Lightning](https://arxiv.org/abs/2402.13929).
     */
    post: operations["StableDiffusionXLLightning"];
  };
  "/StableDiffusionXLInpaint": {
    /**
     * StableDiffusionXLInpaint
     * @description Edit an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952). Supports inpainting (edit part of the image with a mask) and image-to-image (edit the full image).
     */
    post: operations["StableDiffusionXLInpaint"];
  };
  "/StableDiffusionXLIPAdapter": {
    /**
     * StableDiffusionXLIPAdapter
     * @description Generate an image with an image prompt, using Stable Diffusion XL with [IP-Adapter](https://arxiv.org/abs/2308.06721).
     */
    post: operations["StableDiffusionXLIPAdapter"];
  };
  "/StableDiffusionXLControlNet": {
    /**
     * StableDiffusionXLControlNet
     * @description Generate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543).
     */
    post: operations["StableDiffusionXLControlNet"];
  };
  "/FillMask": {
    /**
     * FillMask
     * @description Fill (inpaint) part of an image, e.g. to 'remove' an object.
     */
    post: operations["FillMask"];
  };
  "/BigLaMa": {
    /**
     * BigLaMa
     * @description Inpaint a mask using [LaMa](https://github.com/advimman/lama).
     */
    post: operations["BigLaMa"];
  };
  "/UpscaleImage": {
    /**
     * UpscaleImage
     * @description Upscale an image.
     */
    post: operations["UpscaleImage"];
  };
  "/RealESRGAN": {
    /**
     * RealESRGAN
     * @description Upscale an image using [RealESRGAN](https://github.com/xinntao/Real-ESRGAN).
     */
    post: operations["RealESRGAN"];
  };
  "/RemoveBackground": {
    /**
     * RemoveBackground
     * @description Remove the background from an image, with the option to return the foreground as a mask.
     */
    post: operations["RemoveBackground"];
  };
  "/DISISNet": {
    /**
     * DISISNet
     * @description Segment image foreground using [DIS IS-Net](https://github.com/xuebinqin/DIS).
     */
    post: operations["DISISNet"];
  };
  "/SegmentUnderPoint": {
    /**
     * SegmentUnderPoint
     * @description Segment an image under a point and return the segment.
     */
    post: operations["SegmentUnderPoint"];
  };
  "/SegmentAnything": {
    /**
     * SegmentAnything
     * @description Segment an image using [SegmentAnything](https://github.com/facebookresearch/segment-anything).
     */
    post: operations["SegmentAnything"];
  };
  "/TranscribeMedia": {
    /**
     * TranscribeMedia
     * @description Transcribe speech in an audio or video file.
     */
    post: operations["TranscribeMedia"];
  };
  "/GenerateSpeech": {
    /**
     * GenerateSpeech
     * @description Generate speech from text.
     */
    post: operations["GenerateSpeech"];
  };
  "/XTTSV2": {
    /**
     * XTTSV2
     * @description Generate speech from text using [XTTS v2](https://docs.coqui.ai/en/latest/models/xtts.html).
     */
    post: operations["XTTSV2"];
  };
  "/EmbedText": {
    /**
     * EmbedText
     * @description Generate embedding for a text document.
     */
    post: operations["EmbedText"];
  };
  "/MultiEmbedText": {
    /**
     * MultiEmbedText
     * @description Generate embeddings for multiple text documents.
     */
    post: operations["MultiEmbedText"];
  };
  "/EmbedImage": {
    /**
     * EmbedImage
     * @description Generate embedding for an image.
     */
    post: operations["EmbedImage"];
  };
  "/MultiEmbedImage": {
    /**
     * MultiEmbedImage
     * @description Generate embeddings for multiple images.
     */
    post: operations["MultiEmbedImage"];
  };
  "/JinaV2": {
    /**
     * JinaV2
     * @description Generate embeddings for multiple text documents using [Jina Embeddings 2](https://arxiv.org/abs/2310.19923).
     */
    post: operations["JinaV2"];
  };
  "/CLIP": {
    /**
     * CLIP
     * @description Generate embeddings for text or images using [CLIP](https://openai.com/research/clip).
     */
    post: operations["CLIP"];
  };
  "/CreateVectorStore": {
    /**
     * CreateVectorStore
     * @description Create a vector store for storing and querying embeddings.
     */
    post: operations["CreateVectorStore"];
  };
  "/ListVectorStores": {
    /**
     * ListVectorStores
     * @description List all vector stores.
     */
    post: operations["ListVectorStores"];
  };
  "/DeleteVectorStore": {
    /**
     * DeleteVectorStore
     * @description Delete a vector store.
     */
    post: operations["DeleteVectorStore"];
  };
  "/QueryVectorStore": {
    /**
     * QueryVectorStore
     * @description Query a vector store for similar vectors.
     */
    post: operations["QueryVectorStore"];
  };
  "/FetchVectors": {
    /**
     * FetchVectors
     * @description Fetch vectors from a vector store.
     */
    post: operations["FetchVectors"];
  };
  "/UpdateVectors": {
    /**
     * UpdateVectors
     * @description Update vectors in a vector store.
     */
    post: operations["UpdateVectors"];
  };
  "/DeleteVectors": {
    /**
     * DeleteVectors
     * @description Delete vectors in a vector store.
     */
    post: operations["DeleteVectors"];
  };
}

export type webhooks = Record<string, never>;

export interface components {
  schemas: {
    /** ErrorOut */
    ErrorOut: {
      /**
       * @description The type of error returned.
       * @enum {string}
       */
      type: "api_error" | "invalid_request_error";
      /** @description A message providing more details about the error. */
      message: string;
    };
    /** GenerateTextIn */
    GenerateTextIn: {
      /** @description Input prompt. */
      prompt: string;
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
       * @default 0.4
       */
      temperature?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
      /**
       * @description Selected node.
       * @default Mistral7BInstruct
       * @enum {string}
       */
      node?: "Mistral7BInstruct";
    };
    /** GenerateTextOut */
    GenerateTextOut: {
      /** @description Text response. */
      text?: string;
    };
    /** GenerateJSONIn */
    GenerateJSONIn: {
      /** @description Input prompt. */
      prompt: string;
      /** @description JSON schema to guide `json_object` response. */
      json_schema: {
        [key: string]: unknown;
      };
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
       * @default 0.4
       */
      temperature?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
      /**
       * @description Selected node.
       * @default Mistral7BInstruct
       * @enum {string}
       */
      node?: "Mistral7BInstruct";
    };
    /** GenerateJSONOut */
    GenerateJSONOut: {
      /** @description JSON response. */
      json_object?: {
        [key: string]: unknown;
      };
    };
    /** MultiGenerateTextIn */
    MultiGenerateTextIn: {
      /** @description Input prompt. */
      prompt: string;
      /**
       * @description Number of choices to generate.
       * @default 1
       */
      num_choices: number;
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
       * @default 0.4
       */
      temperature?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
      /**
       * @description Selected node.
       * @default Mistral7BInstruct
       * @enum {string}
       */
      node?: "Mistral7BInstruct";
    };
    /** MultiGenerateTextOut */
    MultiGenerateTextOut: {
      choices: {
        /** @description Text response. */
        text?: string;
      }[];
    };
    /** MultiGenerateJSONIn */
    MultiGenerateJSONIn: {
      /** @description Input prompt. */
      prompt: string;
      /** @description JSON schema to guide `json_object` response. */
      json_schema: {
        [key: string]: unknown;
      };
      /**
       * @description Number of choices to generate.
       * @default 1
       */
      num_choices: number;
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
       * @default 0.4
       */
      temperature?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
      /**
       * @description Selected node.
       * @default Mistral7BInstruct
       * @enum {string}
       */
      node?: "Mistral7BInstruct";
    };
    /** MultiGenerateJSONOut */
    MultiGenerateJSONOut: {
      choices: {
        /** @description JSON response. */
        json_object?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** Mistral7BInstructIn */
    Mistral7BInstructIn: {
      /** @description Input prompt. */
      prompt: string;
      /** @description Number of choices to generate. */
      num_choices: number;
      /** @description JSON schema to guide response. */
      json_schema?: {
        [key: string]: unknown;
      };
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
       */
      temperature?: number;
      /** @description Maximum number of tokens to generate. */
      max_tokens?: number;
    };
    /** Mistral7BInstructChoice */
    Mistral7BInstructChoice: {
      /** @description Text response, if `json_schema` was not provided. */
      text?: string;
      /** @description JSON response, if `json_schema` was provided. */
      json_object?: {
        [key: string]: unknown;
      };
    };
    /** Mistral7BInstructOut */
    Mistral7BInstructOut: {
      choices: {
        /** @description Text response, if `json_schema` was not provided. */
        text?: string;
        /** @description JSON response, if `json_schema` was provided. */
        json_object?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** GenerateTextVisionIn */
    GenerateTextVisionIn: {
      /** @description Text prompt. */
      prompt: string;
      /** @description Image prompts. */
      image_uris: string[];
      /**
       * @description Maximum number of tokens to generate.
       * @default 800
       */
      max_tokens?: number;
      /**
       * @description Selected node.
       * @default Firellava13B
       * @enum {string}
       */
      node?: "Firellava13B";
    };
    /** GenerateTextVisionOut */
    GenerateTextVisionOut: {
      /** @description Text response. */
      text: string;
    };
    /** Firellava13BIn */
    Firellava13BIn: {
      /** @description Text prompt. */
      prompt: string;
      /** @description Image prompts. */
      image_uris: string[];
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
       */
      temperature?: number;
      /**
       * @description Maximum number of tokens to generate.
       * @default 800
       */
      max_tokens?: number;
    };
    /** Firellava13BOut */
    Firellava13BOut: {
      /** @description Text response. */
      text: string;
    };
    /** GenerateImageIn */
    GenerateImageIn: {
      /** @description Text prompt. */
      prompt: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * @description Selected node.
       * @default StableDiffusionXL
       * @enum {string}
       */
      node?: "StableDiffusionXL";
    };
    /** GenerateImageOut */
    GenerateImageOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** MultiGenerateImageIn */
    MultiGenerateImageIn: {
      /** @description Text prompt. */
      prompt: string;
      /** @description Number of images to generate. */
      num_images: number;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * @description Selected node.
       * @default StableDiffusionXL
       * @enum {string}
       */
      node?: "StableDiffusionXL";
    };
    /** MultiGenerateImageOut */
    MultiGenerateImageOut: {
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
      }[];
    };
    /** StableDiffusionXLIn */
    StableDiffusionXLIn: {
      /** @description Text prompt. */
      prompt: string;
      /** @description Negative input prompt. */
      negative_prompt?: string;
      /** @description Number of diffusion steps. */
      steps?: number;
      /**
       * @description Number of images to generate.
       * @default 1
       */
      num_images?: number;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /** @description Height of output image, in pixels. */
      height?: number;
      /** @description Width of output image, in pixels. */
      width?: number;
      /** @description Seeds for deterministic generation. Default is a random seed. */
      seeds?: number[];
      /**
       * Format: float
       * @description Higher values adhere to the text prompt more strongly, typically at the expense of image quality.
       * @default 5
       */
      guidance_scale?: number;
    };
    /** StableDiffusionImage */
    StableDiffusionImage: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
      /** @description The random noise seed used for generation. */
      seed: number;
    };
    /** StableDiffusionXLOut */
    StableDiffusionXLOut: {
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
        /** @description The random noise seed used for generation. */
        seed: number;
      }[];
    };
    /** StableDiffusionXLLightningIn */
    StableDiffusionXLLightningIn: {
      /** @description Text prompt. */
      prompt: string;
      /** @description Negative input prompt. */
      negative_prompt?: string;
      /**
       * @description Number of images to generate.
       * @default 1
       */
      num_images?: number;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /** @description Height of output image, in pixels. */
      height?: number;
      /** @description Width of output image, in pixels. */
      width?: number;
      /** @description Seeds for deterministic generation. Default is a random seed. */
      seeds?: number[];
    };
    /** StableDiffusionXLLightningOut */
    StableDiffusionXLLightningOut: {
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
        /** @description The random noise seed used for generation. */
        seed: number;
      }[];
    };
    /** StableDiffusionXLIPAdapterIn */
    StableDiffusionXLIPAdapterIn: {
      /** @description Text prompt. */
      prompt: string;
      /** @description Image prompt. */
      image_prompt_uri?: string;
      /**
       * @description Number of images to generate.
       * @default 1
       */
      num_images: number;
      /**
       * Format: float
       * @description Controls the influence of the image prompt on the generated output.
       */
      ip_adapter_scale?: number;
      /** @description Negative input prompt. */
      negative_prompt?: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /** @description Width of output image, in pixels. */
      width?: number;
      /** @description Height of output image, in pixels. */
      height?: number;
      /** @description Random noise seeds. Default is random seeds for each generation. */
      seeds?: number[];
    };
    /** StableDiffusionXLIPAdapterOut */
    StableDiffusionXLIPAdapterOut: {
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
        /** @description The random noise seed used for generation. */
        seed: number;
      }[];
    };
    /** StableDiffusionXLControlNetIn */
    StableDiffusionXLControlNetIn: {
      /** @description Input image. */
      image_uri: string;
      /**
       * @description Strategy to control generation using the input image.
       * @enum {string}
       */
      control_method: "edge" | "depth" | "illusion";
      /** @description Text prompt. */
      prompt: string;
      /**
       * @description Number of images to generate.
       * @default 1
       */
      num_images: number;
      /**
       * @description Resolution of the output image, in pixels.
       * @default 1024
       */
      output_resolution?: number;
      /** @description Negative input prompt. */
      negative_prompt?: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * Format: float
       * @description Controls the influence of the input image on the generated output.
       */
      conditioning_scale?: number;
      /** @description Random noise seeds. Default is random seeds for each generation. */
      seeds?: number[];
    };
    /** StableDiffusionXLControlNetOut */
    StableDiffusionXLControlNetOut: {
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
        /** @description The random noise seed used for generation. */
        seed: number;
      }[];
    };
    /** GenerativeEditImageIn */
    GenerativeEditImageIn: {
      /** @description Original image. */
      image_uri: string;
      /** @description Text prompt. */
      prompt: string;
      /** @description Mask image that controls which pixels are inpainted. If unset, the entire image is edited (image-to-image). */
      mask_image_uri?: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * @description Selected node.
       * @default StableDiffusionXLInpaint
       * @enum {string}
       */
      node?: "StableDiffusionXLInpaint";
    };
    /** GenerativeEditImageOut */
    GenerativeEditImageOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** MultiGenerativeEditImageIn */
    MultiGenerativeEditImageIn: {
      /** @description Original image. */
      image_uri: string;
      /** @description Text prompt. */
      prompt: string;
      /** @description Mask image that controls which pixels are edited (inpainting). If unset, the entire image is edited (image-to-image). */
      mask_image_uri?: string;
      /** @description Number of images to generate. */
      num_images: number;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * @description Selected node.
       * @default StableDiffusionXLInpaint
       * @enum {string}
       */
      node?: "StableDiffusionXLInpaint";
    };
    /** MultiGenerativeEditImageOut */
    MultiGenerativeEditImageOut: {
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
      }[];
    };
    /** StableDiffusionXLInpaintIn */
    StableDiffusionXLInpaintIn: {
      /** @description Original image. */
      image_uri: string;
      /** @description Text prompt. */
      prompt: string;
      /** @description Mask image that controls which pixels are edited (inpainting). If unset, the entire image is edited (image-to-image). */
      mask_image_uri?: string;
      /**
       * @description Number of images to generate.
       * @default 1
       */
      num_images: number;
      /**
       * @description Resolution of the output image, in pixels.
       * @default 1024
       */
      output_resolution?: number;
      /** @description Negative input prompt. */
      negative_prompt?: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * Format: float
       * @description Controls the strength of the generation process.
       * @default 1
       */
      strength?: number;
      /** @description Random noise seeds. Default is random seeds for each generation. */
      seeds?: number[];
    };
    /** StableDiffusionXLInpaintOut */
    StableDiffusionXLInpaintOut: {
      outputs: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
        image_uri: string;
        /** @description The random noise seed used for generation. */
        seed: number;
      }[];
    };
    /** BoundingBox */
    BoundingBox: {
      /**
       * Format: float
       * @description Top left corner x.
       */
      x1: number;
      /**
       * Format: float
       * @description Top left corner y.
       */
      y1: number;
      /**
       * Format: float
       * @description Bottom right corner x.
       */
      x2: number;
      /**
       * Format: float
       * @description Bottom right corner y.
       */
      y2: number;
    };
    /** Point */
    Point: {
      /** @description X position. */
      x: number;
      /** @description Y position. */
      y: number;
    };
    /** FillMaskIn */
    FillMaskIn: {
      /** @description Input image. */
      image_uri: string;
      /** @description Mask image that controls which pixels are inpainted. */
      mask_image_uri: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * @description Selected node.
       * @default BigLaMa
       * @enum {string}
       */
      node?: "BigLaMa";
    };
    /** FillMaskOut */
    FillMaskOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** BigLaMaIn */
    BigLaMaIn: {
      /** @description Input image. */
      image_uri: string;
      /** @description Mask image that controls which pixels are inpainted. */
      mask_image_uri: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** BigLaMaOut */
    BigLaMaOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** RemoveBackgroundIn */
    RemoveBackgroundIn: {
      /** @description Input image. */
      image_uri: string;
      /**
       * @description Return a mask image instead of the original content.
       * @default false
       */
      return_mask?: boolean;
      /** @description Hex value background color. Transparent if unset. */
      background_color?: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * @description Selected node.
       * @default DISISNet
       * @enum {string}
       */
      node?: "DISISNet";
    };
    /** RemoveBackgroundOut */
    RemoveBackgroundOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** DISISNetIn */
    DISISNetIn: {
      /** @description Input image. */
      image_uri: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** DISISNetOut */
    DISISNetOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** UpscaleImageIn */
    UpscaleImageIn: {
      /** @description Input image. */
      image_uri: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * @description Selected node.
       * @default RealESRGAN
       * @enum {string}
       */
      node?: "RealESRGAN";
    };
    /** UpscaleImageOut */
    UpscaleImageOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** RealESRGANIn */
    RealESRGANIn: {
      /** @description Input image. */
      image_uri: string;
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** RealESRGANOut */
    RealESRGANOut: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      image_uri: string;
    };
    /** SegmentUnderPointIn */
    SegmentUnderPointIn: {
      /** @description Input image. */
      image_uri: string;
      /** Point */
      point: {
        /** @description X position. */
        x: number;
        /** @description Y position. */
        y: number;
      };
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * @description Selected node.
       * @default SegmentAnything
       * @enum {string}
       */
      node?: "SegmentAnything";
    };
    /** SegmentUnderPointOut */
    SegmentUnderPointOut: {
      /** @description Detected segments in 'mask image' format. Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      mask_image_uri: string;
    };
    /** SegmentAnythingIn */
    SegmentAnythingIn: {
      /** @description Input image. */
      image_uri: string;
      /** @description Point prompts, to detect a segment under the point. One of `point_prompts` or `box_prompts` must be set. */
      point_prompts?: {
        /** @description X position. */
        x: number;
        /** @description Y position. */
        y: number;
      }[];
      /** @description Box prompts, to detect a segment within the bounding box. One of `point_prompts` or `box_prompts` must be set. */
      box_prompts?: {
        /**
         * Format: float
         * @description Top left corner x.
         */
        x1: number;
        /**
         * Format: float
         * @description Top left corner y.
         */
        y1: number;
        /**
         * Format: float
         * @description Bottom right corner x.
         */
        x2: number;
        /**
         * Format: float
         * @description Bottom right corner y.
         */
        y2: number;
      }[];
      /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** SegmentAnythingOut */
    SegmentAnythingOut: {
      /** @description Detected segments in 'mask image' format. Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
      mask_image_uri: string;
    };
    /** TranscribeMediaIn */
    TranscribeMediaIn: {
      /** @description Input audio. */
      audio_uri: string;
      /** @description Prompt to guide model on the content and context of input audio. */
      prompt?: string;
      /**
       * @description Language of input audio in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes) format.
       * @default en
       */
      language?: string;
      /**
       * @description Segment the text into sentences with approximate timestamps.
       * @default false
       */
      segment?: boolean;
      /**
       * @description Align transcription to produce more accurate sentence-level timestamps and word-level timestamps. An array of word segments will be included in each sentence segment.
       * @default false
       */
      align?: boolean;
      /**
       * @description Identify speakers for each segment. Speaker IDs will be included in each segment.
       * @default false
       */
      diarize?: boolean;
      /**
       * @description Suggest automatic chapter markers.
       * @default false
       */
      suggest_chapters?: boolean;
    };
    /** TranscribedWord */
    TranscribedWord: {
      /** @description Text of word. */
      word: string;
      /**
       * Format: float
       * @description Start time of word, in seconds.
       */
      start?: number;
      /**
       * Format: float
       * @description End time of word, in seconds.
       */
      end?: number;
      /** @description ID of speaker, if `diarize` is enabled. */
      speaker?: string;
    };
    /** TranscribedSegment */
    TranscribedSegment: {
      /** @description Text of segment. */
      text: string;
      /**
       * Format: float
       * @description Start time of segment, in seconds.
       */
      start: number;
      /**
       * Format: float
       * @description End time of segment, in seconds.
       */
      end: number;
      /** @description ID of speaker, if `diarize` is enabled. */
      speaker?: string;
      /** @description Aligned words, if `align` is enabled. */
      words?: {
        /** @description Text of word. */
        word: string;
        /**
         * Format: float
         * @description Start time of word, in seconds.
         */
        start?: number;
        /**
         * Format: float
         * @description End time of word, in seconds.
         */
        end?: number;
        /** @description ID of speaker, if `diarize` is enabled. */
        speaker?: string;
      }[];
    };
    /** ChapterMarker */
    ChapterMarker: {
      /** @description Chapter title. */
      title: string;
      /**
       * Format: float
       * @description Start time of chapter, in seconds.
       */
      start: number;
    };
    /** TranscribeMediaOut */
    TranscribeMediaOut: {
      /** @description Transcribed text. */
      text: string;
      /** @description Transcribed segments, if `segment` is enabled. */
      segments?: {
        /** @description Text of segment. */
        text: string;
        /**
         * Format: float
         * @description Start time of segment, in seconds.
         */
        start: number;
        /**
         * Format: float
         * @description End time of segment, in seconds.
         */
        end: number;
        /** @description ID of speaker, if `diarize` is enabled. */
        speaker?: string;
        /** @description Aligned words, if `align` is enabled. */
        words?: {
          /** @description Text of word. */
          word: string;
          /**
           * Format: float
           * @description Start time of word, in seconds.
           */
          start?: number;
          /**
           * Format: float
           * @description End time of word, in seconds.
           */
          end?: number;
          /** @description ID of speaker, if `diarize` is enabled. */
          speaker?: string;
        }[];
      }[];
      /** @description Chapter markers, if `suggest_chapters` is enabled. */
      chapters?: {
        /** @description Chapter title. */
        title: string;
        /**
         * Format: float
         * @description Start time of chapter, in seconds.
         */
        start: number;
      }[];
    };
    /** GenerateSpeechIn */
    GenerateSpeechIn: {
      /** @description Input text. */
      text: string;
      /** @description Use "hosted" to return an audio URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the audio data will be returned as a base64-encoded string. */
      store?: string;
      /**
       * @description Selected node.
       * @default XTTSV2
       * @enum {string}
       */
      node?: "XTTSV2";
    };
    /** GenerateSpeechOut */
    GenerateSpeechOut: {
      /** @description Base 64-encoded WAV audio bytes, or a hosted audio url if `store` is provided. */
      audio_uri: string;
    };
    /** XTTSV2In */
    XTTSV2In: {
      /** @description Input text. */
      text: string;
      /** @description Reference audio used to synthesize the speaker. If unset, a default speaker voice will be used. */
      audio_uri?: string;
      /**
       * @description Language of input text. Supported languages: `en, de, fr, es, it, pt, pl, zh, ar, cs, ru, nl, tr, hu, ko`.
       * @default en
       */
      language?: string;
      /** @description Use "hosted" to return an audio URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the audio data will be returned as a base64-encoded string. */
      store?: string;
    };
    /** XTTSV2Out */
    XTTSV2Out: {
      /** @description Base 64-encoded WAV audio bytes, or a hosted audio url if `store` is provided. */
      audio_uri: string;
    };
    /** Embedding */
    Embedding: {
      /** @description Embedding vector. */
      vector: number[];
      /** @description Vector store document ID. */
      doc_id?: string;
      /** @description Vector store document metadata. */
      metadata?: {
        [key: string]: unknown;
      };
    };
    /** EmbedTextIn */
    EmbedTextIn: {
      /** @description Text to embed. */
      text: string;
      /** @description [Vector store](/docs/vector-stores) identifier. */
      store?: string;
      /** @description Metadata that can be used to query the vector store. Ignored if `store` is unset. */
      metadata?: {
        [key: string]: unknown;
      };
      /** @description Choose keys from `metadata` to embed with text. */
      embedded_metadata_keys?: string[];
      /** @description Vector store document ID. Ignored if `store` is unset. */
      doc_id?: string;
      /**
       * @description Selected node.
       * @default JinaV2
       * @enum {string}
       */
      node?: "JinaV2" | "CLIP";
    };
    /** EmbedTextOut */
    EmbedTextOut: {
      /** Embedding */
      embedding: {
        /** @description Embedding vector. */
        vector: number[];
        /** @description Vector store document ID. */
        doc_id?: string;
        /** @description Vector store document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      };
    };
    /** EmbedTextItem */
    EmbedTextItem: {
      /** @description Text to embed. */
      text: string;
      /** @description Metadata that can be used to query the vector store. Ignored if `store` is unset. */
      metadata?: {
        [key: string]: unknown;
      };
      /** @description Vector store document ID. Ignored if `store` is unset. */
      doc_id?: string;
    };
    /** MultiEmbedTextIn */
    MultiEmbedTextIn: {
      /** @description Items to embed. */
      items: {
        /** @description Text to embed. */
        text: string;
        /** @description Metadata that can be used to query the vector store. Ignored if `store` is unset. */
        metadata?: {
          [key: string]: unknown;
        };
        /** @description Vector store document ID. Ignored if `store` is unset. */
        doc_id?: string;
      }[];
      /** @description [Vector store](/docs/vector-stores) identifier. */
      store?: string;
      /** @description Choose keys from `metadata` to embed with text. */
      embedded_metadata_keys?: string[];
      /**
       * @description Selected node.
       * @default JinaV2
       * @enum {string}
       */
      node?: "JinaV2" | "CLIP";
    };
    /** MultiEmbedTextOut */
    MultiEmbedTextOut: {
      /** @description Generated embeddings. */
      embeddings: {
        /** @description Embedding vector. */
        vector: number[];
        /** @description Vector store document ID. */
        doc_id?: string;
        /** @description Vector store document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** JinaV2In */
    JinaV2In: {
      /** @description Items to embed. */
      items: {
        /** @description Text to embed. */
        text: string;
        /** @description Metadata that can be used to query the vector store. Ignored if `store` is unset. */
        metadata?: {
          [key: string]: unknown;
        };
        /** @description Vector store document ID. Ignored if `store` is unset. */
        doc_id?: string;
      }[];
      /** @description [Vector store](/docs/vector-stores) identifier. */
      store?: string;
      /** @description Choose keys from `metadata` to embed with text. */
      embedded_metadata_keys?: string[];
    };
    /** JinaV2Out */
    JinaV2Out: {
      /** @description Generated embeddings. */
      embeddings: {
        /** @description Embedding vector. */
        vector: number[];
        /** @description Vector store document ID. */
        doc_id?: string;
        /** @description Vector store document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** EmbedImageIn */
    EmbedImageIn: {
      /** @description Image to embed. */
      image_uri: string;
      /** @description [Vector store](/docs/vector-stores) identifier. */
      store?: string;
      /** @description Vector store document ID. Ignored if `store` is unset. */
      doc_id?: string;
      /**
       * @description Selected node.
       * @default CLIP
       * @enum {string}
       */
      node?: "CLIP";
    };
    /** EmbedImageOut */
    EmbedImageOut: {
      /** Embedding */
      embedding: {
        /** @description Embedding vector. */
        vector: number[];
        /** @description Vector store document ID. */
        doc_id?: string;
        /** @description Vector store document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      };
    };
    /** EmbedImageItem */
    EmbedImageItem: {
      /** @description Image to embed. */
      image_uri: string;
      /** @description Vector store document ID. Ignored if `store` is unset. */
      doc_id?: string;
    };
    /** EmbedTextOrImageItem */
    EmbedTextOrImageItem: {
      /** @description Image to embed. */
      image_uri?: string;
      /** @description Text to embed. */
      text?: string;
      /** @description Metadata that can be used to query the vector store. Ignored if `store` is unset. */
      metadata?: {
        [key: string]: unknown;
      };
      /** @description Vector store document ID. Ignored if `store` is unset. */
      doc_id?: string;
    };
    /** MultiEmbedImageIn */
    MultiEmbedImageIn: {
      /** @description Items to embed. */
      items: {
        /** @description Image to embed. */
        image_uri: string;
        /** @description Vector store document ID. Ignored if `store` is unset. */
        doc_id?: string;
      }[];
      /** @description [Vector store](/docs/vector-stores) identifier. */
      store?: string;
      /**
       * @description Selected node.
       * @default CLIP
       * @enum {string}
       */
      node?: "CLIP";
    };
    /** MultiEmbedImageOut */
    MultiEmbedImageOut: {
      /** @description Generated embeddings. */
      embeddings: {
        /** @description Embedding vector. */
        vector: number[];
        /** @description Vector store document ID. */
        doc_id?: string;
        /** @description Vector store document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** CLIPIn */
    CLIPIn: {
      /** @description Items to embed. */
      items: {
        /** @description Image to embed. */
        image_uri?: string;
        /** @description Text to embed. */
        text?: string;
        /** @description Metadata that can be used to query the vector store. Ignored if `store` is unset. */
        metadata?: {
          [key: string]: unknown;
        };
        /** @description Vector store document ID. Ignored if `store` is unset. */
        doc_id?: string;
      }[];
      /** @description Choose keys from `metadata` to embed with text, when embedding and storing text documents. */
      embedded_metadata_keys?: string[];
      /** @description [Vector store](/docs/vector-stores) identifier. */
      store?: string;
    };
    /** CLIPOut */
    CLIPOut: {
      /** @description Generated embeddings. */
      embeddings: {
        /** @description Embedding vector. */
        vector: number[];
        /** @description Vector store document ID. */
        doc_id?: string;
        /** @description Vector store document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** CreateVectorStoreIn */
    CreateVectorStoreIn: {
      /** @description Vector store name. */
      name: string;
      /**
       * @description Selected embedding model
       * @enum {string}
       */
      model: "jina-v2" | "clip";
      /**
       * @description The max number of connections per layer for the index.
       * @default 16
       */
      m?: number;
      /**
       * @description The size of the dynamic candidate list for constructing the index graph.
       * @default 64
       */
      ef_construction?: number;
      /**
       * @description The distance metric to construct the index with.
       * @default inner
       * @enum {string}
       */
      metric?: "cosine" | "l2" | "inner";
    };
    /** CreateVectorStoreOut */
    CreateVectorStoreOut: {
      /** @description Vector store name. */
      name: string;
      /**
       * @description Selected embedding model
       * @enum {string}
       */
      model: "jina-v2" | "clip";
      /**
       * @description The max number of connections per layer for the index.
       * @default 16
       */
      m: number;
      /**
       * @description The size of the dynamic candidate list for constructing the index graph.
       * @default 64
       */
      ef_construction: number;
      /**
       * @description The distance metric to construct the index with.
       * @default inner
       * @enum {string}
       */
      metric: "cosine" | "l2" | "inner";
    };
    /** ListVectorStoresIn */
    ListVectorStoresIn: Record<string, never>;
    /** ListVectorStoresOut */
    ListVectorStoresOut: {
      /** @description List of vector stores. */
      stores?: {
        /** @description Vector store name. */
        name: string;
        /**
         * @description Selected embedding model
         * @enum {string}
         */
        model: "jina-v2" | "clip";
        /**
         * @description The max number of connections per layer for the index.
         * @default 16
         */
        m: number;
        /**
         * @description The size of the dynamic candidate list for constructing the index graph.
         * @default 64
         */
        ef_construction: number;
        /**
         * @description The distance metric to construct the index with.
         * @default inner
         * @enum {string}
         */
        metric: "cosine" | "l2" | "inner";
      }[];
    };
    /** DeleteVectorStoreIn */
    DeleteVectorStoreIn: {
      /** @description Vector store name. */
      name: string;
      /**
       * @description Selected embedding model
       * @enum {string}
       */
      model: "jina-v2" | "clip";
    };
    /** DeleteVectorStoreOut */
    DeleteVectorStoreOut: {
      /** @description Vector store name. */
      name: string;
      /**
       * @description Selected embedding model
       * @enum {string}
       */
      model: "jina-v2" | "clip";
    };
    /**
     * Vector
     * @description Canonical representation of document with embedding vector.
     */
    Vector: {
      /** @description Document ID. */
      id: string;
      /** @description Embedding vector. */
      vector: number[];
      /** @description Document metadata. */
      metadata: {
        [key: string]: unknown;
      };
    };
    /** FetchVectorsIn */
    FetchVectorsIn: {
      /** @description Vector store name. */
      name: string;
      /**
       * @description Selected embedding model
       * @enum {string}
       */
      model: "jina-v2" | "clip";
      /** @description Document IDs to retrieve. */
      ids: string[];
    };
    /** FetchVectorsOut */
    FetchVectorsOut: {
      /** @description Retrieved vectors. */
      vectors: {
        /** @description Document ID. */
        id: string;
        /** @description Embedding vector. */
        vector: number[];
        /** @description Document metadata. */
        metadata: {
          [key: string]: unknown;
        };
      }[];
    };
    /** UpdateVectorsOut */
    UpdateVectorsOut: {
      /** @description Number of vectors modified. */
      count: number;
    };
    /** DeleteVectorsOut */
    DeleteVectorsOut: {
      /** @description Number of vectors modified. */
      count: number;
    };
    /** UpdateVectorParams */
    UpdateVectorParams: {
      /** @description Document ID. */
      id: string;
      /** @description Embedding vector. */
      vector?: number[];
      /** @description Document metadata. */
      metadata?: {
        [key: string]: unknown;
      };
    };
    /** UpdateVectorsIn */
    UpdateVectorsIn: {
      /** @description Vector store name. */
      name: string;
      /**
       * @description Selected embedding model
       * @enum {string}
       */
      model: "jina-v2" | "clip";
      /** @description Vectors to upsert. */
      vectors: {
        /** @description Document ID. */
        id: string;
        /** @description Embedding vector. */
        vector?: number[];
        /** @description Document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      }[];
    };
    /** DeleteVectorsIn */
    DeleteVectorsIn: {
      /** @description Vector store name. */
      name: string;
      /**
       * @description Selected embedding model
       * @enum {string}
       */
      model: "jina-v2" | "clip";
      /** @description Document IDs to delete. */
      ids: string[];
    };
    /** QueryVectorStoreIn */
    QueryVectorStoreIn: {
      /** @description Vector store to query against. */
      name: string;
      /**
       * @description Selected embedding model
       * @enum {string}
       */
      model: "jina-v2" | "clip";
      /** @description Document IDs to use for the query. */
      query_ids?: string[];
      /** @description Image URIs to embed and use for the query. */
      query_image_uris?: string[];
      /** @description Vector to use for the query. */
      query_vectors?: number[][];
      /** @description Texts to embed and use for the query. */
      query_strings?: string[];
      /**
       * @description Number of results to return.
       * @default 10
       */
      top_k?: number;
      /**
       * @description The size of the dynamic candidate list for searching the index graph.
       * @default 40
       */
      ef_search?: number;
      /**
       * @description Include the values of the vectors in the response.
       * @default false
       */
      include_values?: boolean;
      /**
       * @description Include the metadata of the vectors in the response.
       * @default false
       */
      include_metadata?: boolean;
      /** @description Filter metadata by key-value pairs. */
      filters?: {
        [key: string]: unknown;
      };
      /**
       * @description The distance metric used for the query. Defaults to the distance metric the vector store was created with.
       * @enum {string}
       */
      metric?: "cosine" | "l2" | "inner";
    };
    /** VectorStoreQueryResult */
    VectorStoreQueryResult: {
      /** @description Document ID. */
      id: string;
      /**
       * Format: float
       * @description Similarity score.
       */
      distance: number;
      /** @description Embedding vector. */
      vector?: number[];
      /** @description Document metadata. */
      metadata?: {
        [key: string]: unknown;
      };
    };
    /** QueryVectorStoreOut */
    QueryVectorStoreOut: {
      /** @description Query results. */
      results: {
        /** @description Document ID. */
        id: string;
        /**
         * Format: float
         * @description Similarity score.
         */
        distance: number;
        /** @description Embedding vector. */
        vector?: number[];
        /** @description Document metadata. */
        metadata?: {
          [key: string]: unknown;
        };
      }[][];
      /** @description Vector store name. */
      name?: string;
      /**
       * @description Selected embedding model
       * @enum {string}
       */
      model?: "jina-v2" | "clip";
      /**
       * @description The distance metric used for the query.
       * @enum {string}
       */
      metric?: "cosine" | "l2" | "inner";
    };
  };
  responses: never;
  parameters: never;
  requestBodies: never;
  headers: never;
  pathItems: never;
}

export type $defs = Record<string, never>;

export type external = Record<string, never>;

export interface operations {
  /**
   * GenerateText
   * @description Generate text using a language model.
   */
  GenerateText: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input prompt. */
          prompt: string;
          /**
           * Format: float
           * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
           * @default 0.4
           */
          temperature?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
          /**
           * @description Selected node.
           * @default Mistral7BInstruct
           * @enum {string}
           */
          node?: "Mistral7BInstruct";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Text response. */
            text?: string;
          };
        };
      };
    };
  };
  /**
   * MultiGenerateText
   * @description Generate multiple text choices using a language model.
   */
  MultiGenerateText: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input prompt. */
          prompt: string;
          /**
           * @description Number of choices to generate.
           * @default 1
           */
          num_choices: number;
          /**
           * Format: float
           * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
           * @default 0.4
           */
          temperature?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
          /**
           * @description Selected node.
           * @default Mistral7BInstruct
           * @enum {string}
           */
          node?: "Mistral7BInstruct";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            choices: {
              /** @description Text response. */
              text?: string;
            }[];
          };
        };
      };
    };
  };
  /**
   * GenerateJSON
   * @description Generate JSON using a language model.
   */
  GenerateJSON: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input prompt. */
          prompt: string;
          /** @description JSON schema to guide `json_object` response. */
          json_schema: {
            [key: string]: unknown;
          };
          /**
           * Format: float
           * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
           * @default 0.4
           */
          temperature?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
          /**
           * @description Selected node.
           * @default Mistral7BInstruct
           * @enum {string}
           */
          node?: "Mistral7BInstruct";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description JSON response. */
            json_object?: {
              [key: string]: unknown;
            };
          };
        };
      };
    };
  };
  /**
   * MultiGenerateJSON
   * @description Generate multiple JSON choices using a language model.
   */
  MultiGenerateJSON: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input prompt. */
          prompt: string;
          /** @description JSON schema to guide `json_object` response. */
          json_schema: {
            [key: string]: unknown;
          };
          /**
           * @description Number of choices to generate.
           * @default 1
           */
          num_choices: number;
          /**
           * Format: float
           * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
           * @default 0.4
           */
          temperature?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
          /**
           * @description Selected node.
           * @default Mistral7BInstruct
           * @enum {string}
           */
          node?: "Mistral7BInstruct";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            choices: {
              /** @description JSON response. */
              json_object?: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * GenerateTextVision
   * @description Generate text with image input.
   */
  GenerateTextVision: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Text prompt. */
          prompt: string;
          /** @description Image prompts. */
          image_uris: string[];
          /**
           * @description Maximum number of tokens to generate.
           * @default 800
           */
          max_tokens?: number;
          /**
           * @description Selected node.
           * @default Firellava13B
           * @enum {string}
           */
          node?: "Firellava13B";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Text response. */
            text: string;
          };
        };
      };
    };
  };
  /**
   * Mistral7BInstruct
   * @description Generate text using [Mistral 7B Instruct](https://mistral.ai/news/announcing-mistral-7b).
   */
  Mistral7BInstruct: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input prompt. */
          prompt: string;
          /** @description Number of choices to generate. */
          num_choices: number;
          /** @description JSON schema to guide response. */
          json_schema?: {
            [key: string]: unknown;
          };
          /**
           * Format: float
           * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
           */
          temperature?: number;
          /** @description Maximum number of tokens to generate. */
          max_tokens?: number;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            choices: {
              /** @description Text response, if `json_schema` was not provided. */
              text?: string;
              /** @description JSON response, if `json_schema` was provided. */
              json_object?: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * Firellava13B
   * @description Generate text with image input using [FireLLaVA 13B](https://fireworks.ai/blog/firellava-the-first-commercially-permissive-oss-llava-model).
   */
  Firellava13B: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Text prompt. */
          prompt: string;
          /** @description Image prompts. */
          image_uris: string[];
          /**
           * Format: float
           * @description Sampling temperature to use. Higher values make the output more random, lower values make the output more deterministic.
           */
          temperature?: number;
          /**
           * @description Maximum number of tokens to generate.
           * @default 800
           */
          max_tokens?: number;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Text response. */
            text: string;
          };
        };
      };
    };
  };
  /**
   * GenerateImage
   * @description Generate an image.
   */
  GenerateImage: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Text prompt. */
          prompt: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * @description Selected node.
           * @default StableDiffusionXL
           * @enum {string}
           */
          node?: "StableDiffusionXL";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            image_uri: string;
          };
        };
      };
    };
  };
  /**
   * MultiGenerateImage
   * @description Generate multiple images.
   */
  MultiGenerateImage: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Text prompt. */
          prompt: string;
          /** @description Number of images to generate. */
          num_images: number;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * @description Selected node.
           * @default StableDiffusionXL
           * @enum {string}
           */
          node?: "StableDiffusionXL";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            outputs: {
              /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
              image_uri: string;
            }[];
          };
        };
      };
    };
  };
  /**
   * GenerativeEditImage
   * @description Edit an image using image generation.
   */
  GenerativeEditImage: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Original image. */
          image_uri: string;
          /** @description Text prompt. */
          prompt: string;
          /** @description Mask image that controls which pixels are inpainted. If unset, the entire image is edited (image-to-image). */
          mask_image_uri?: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * @description Selected node.
           * @default StableDiffusionXLInpaint
           * @enum {string}
           */
          node?: "StableDiffusionXLInpaint";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            image_uri: string;
          };
        };
      };
    };
  };
  /**
   * MultiGenerativeEditImage
   * @description Edit multiple images using image generation.
   */
  MultiGenerativeEditImage: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Original image. */
          image_uri: string;
          /** @description Text prompt. */
          prompt: string;
          /** @description Mask image that controls which pixels are edited (inpainting). If unset, the entire image is edited (image-to-image). */
          mask_image_uri?: string;
          /** @description Number of images to generate. */
          num_images: number;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * @description Selected node.
           * @default StableDiffusionXLInpaint
           * @enum {string}
           */
          node?: "StableDiffusionXLInpaint";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            outputs: {
              /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
              image_uri: string;
            }[];
          };
        };
      };
    };
  };
  /**
   * StableDiffusionXL
   * @description Generate an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952).
   */
  StableDiffusionXL: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Text prompt. */
          prompt: string;
          /** @description Negative input prompt. */
          negative_prompt?: string;
          /** @description Number of diffusion steps. */
          steps?: number;
          /**
           * @description Number of images to generate.
           * @default 1
           */
          num_images?: number;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /** @description Height of output image, in pixels. */
          height?: number;
          /** @description Width of output image, in pixels. */
          width?: number;
          /** @description Seeds for deterministic generation. Default is a random seed. */
          seeds?: number[];
          /**
           * Format: float
           * @description Higher values adhere to the text prompt more strongly, typically at the expense of image quality.
           * @default 5
           */
          guidance_scale?: number;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            outputs: {
              /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
              image_uri: string;
              /** @description The random noise seed used for generation. */
              seed: number;
            }[];
          };
        };
      };
    };
  };
  /**
   * StableDiffusionXLLightning
   * @description Generate an image using [Stable Diffusion XL Lightning](https://arxiv.org/abs/2402.13929).
   */
  StableDiffusionXLLightning: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Text prompt. */
          prompt: string;
          /** @description Negative input prompt. */
          negative_prompt?: string;
          /**
           * @description Number of images to generate.
           * @default 1
           */
          num_images?: number;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /** @description Height of output image, in pixels. */
          height?: number;
          /** @description Width of output image, in pixels. */
          width?: number;
          /** @description Seeds for deterministic generation. Default is a random seed. */
          seeds?: number[];
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            outputs: {
              /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
              image_uri: string;
              /** @description The random noise seed used for generation. */
              seed: number;
            }[];
          };
        };
      };
    };
  };
  /**
   * StableDiffusionXLInpaint
   * @description Edit an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952). Supports inpainting (edit part of the image with a mask) and image-to-image (edit the full image).
   */
  StableDiffusionXLInpaint: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Original image. */
          image_uri: string;
          /** @description Text prompt. */
          prompt: string;
          /** @description Mask image that controls which pixels are edited (inpainting). If unset, the entire image is edited (image-to-image). */
          mask_image_uri?: string;
          /**
           * @description Number of images to generate.
           * @default 1
           */
          num_images: number;
          /**
           * @description Resolution of the output image, in pixels.
           * @default 1024
           */
          output_resolution?: number;
          /** @description Negative input prompt. */
          negative_prompt?: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * Format: float
           * @description Controls the strength of the generation process.
           * @default 1
           */
          strength?: number;
          /** @description Random noise seeds. Default is random seeds for each generation. */
          seeds?: number[];
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            outputs: {
              /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
              image_uri: string;
              /** @description The random noise seed used for generation. */
              seed: number;
            }[];
          };
        };
      };
    };
  };
  /**
   * StableDiffusionXLIPAdapter
   * @description Generate an image with an image prompt, using Stable Diffusion XL with [IP-Adapter](https://arxiv.org/abs/2308.06721).
   */
  StableDiffusionXLIPAdapter: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Text prompt. */
          prompt: string;
          /** @description Image prompt. */
          image_prompt_uri?: string;
          /**
           * @description Number of images to generate.
           * @default 1
           */
          num_images: number;
          /**
           * Format: float
           * @description Controls the influence of the image prompt on the generated output.
           */
          ip_adapter_scale?: number;
          /** @description Negative input prompt. */
          negative_prompt?: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /** @description Width of output image, in pixels. */
          width?: number;
          /** @description Height of output image, in pixels. */
          height?: number;
          /** @description Random noise seeds. Default is random seeds for each generation. */
          seeds?: number[];
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            outputs: {
              /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
              image_uri: string;
              /** @description The random noise seed used for generation. */
              seed: number;
            }[];
          };
        };
      };
    };
  };
  /**
   * StableDiffusionXLControlNet
   * @description Generate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543).
   */
  StableDiffusionXLControlNet: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input image. */
          image_uri: string;
          /**
           * @description Strategy to control generation using the input image.
           * @enum {string}
           */
          control_method: "edge" | "depth" | "illusion";
          /** @description Text prompt. */
          prompt: string;
          /**
           * @description Number of images to generate.
           * @default 1
           */
          num_images: number;
          /**
           * @description Resolution of the output image, in pixels.
           * @default 1024
           */
          output_resolution?: number;
          /** @description Negative input prompt. */
          negative_prompt?: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * Format: float
           * @description Controls the influence of the input image on the generated output.
           */
          conditioning_scale?: number;
          /** @description Random noise seeds. Default is random seeds for each generation. */
          seeds?: number[];
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            outputs: {
              /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
              image_uri: string;
              /** @description The random noise seed used for generation. */
              seed: number;
            }[];
          };
        };
      };
    };
  };
  /**
   * FillMask
   * @description Fill (inpaint) part of an image, e.g. to 'remove' an object.
   */
  FillMask: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input image. */
          image_uri: string;
          /** @description Mask image that controls which pixels are inpainted. */
          mask_image_uri: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * @description Selected node.
           * @default BigLaMa
           * @enum {string}
           */
          node?: "BigLaMa";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            image_uri: string;
          };
        };
      };
    };
  };
  /**
   * BigLaMa
   * @description Inpaint a mask using [LaMa](https://github.com/advimman/lama).
   */
  BigLaMa: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input image. */
          image_uri: string;
          /** @description Mask image that controls which pixels are inpainted. */
          mask_image_uri: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            image_uri: string;
          };
        };
      };
    };
  };
  /**
   * UpscaleImage
   * @description Upscale an image.
   */
  UpscaleImage: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input image. */
          image_uri: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * @description Selected node.
           * @default RealESRGAN
           * @enum {string}
           */
          node?: "RealESRGAN";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            image_uri: string;
          };
        };
      };
    };
  };
  /**
   * RealESRGAN
   * @description Upscale an image using [RealESRGAN](https://github.com/xinntao/Real-ESRGAN).
   */
  RealESRGAN: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input image. */
          image_uri: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            image_uri: string;
          };
        };
      };
    };
  };
  /**
   * RemoveBackground
   * @description Remove the background from an image, with the option to return the foreground as a mask.
   */
  RemoveBackground: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input image. */
          image_uri: string;
          /**
           * @description Return a mask image instead of the original content.
           * @default false
           */
          return_mask?: boolean;
          /** @description Hex value background color. Transparent if unset. */
          background_color?: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * @description Selected node.
           * @default DISISNet
           * @enum {string}
           */
          node?: "DISISNet";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            image_uri: string;
          };
        };
      };
    };
  };
  /**
   * DISISNet
   * @description Segment image foreground using [DIS IS-Net](https://github.com/xuebinqin/DIS).
   */
  DISISNet: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input image. */
          image_uri: string;
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            image_uri: string;
          };
        };
      };
    };
  };
  /**
   * SegmentUnderPoint
   * @description Segment an image under a point and return the segment.
   */
  SegmentUnderPoint: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input image. */
          image_uri: string;
          /** Point */
          point: {
            /** @description X position. */
            x: number;
            /** @description Y position. */
            y: number;
          };
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * @description Selected node.
           * @default SegmentAnything
           * @enum {string}
           */
          node?: "SegmentAnything";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Detected segments in 'mask image' format. Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            mask_image_uri: string;
          };
        };
      };
    };
  };
  /**
   * SegmentAnything
   * @description Segment an image using [SegmentAnything](https://github.com/facebookresearch/segment-anything).
   */
  SegmentAnything: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input image. */
          image_uri: string;
          /** @description Point prompts, to detect a segment under the point. One of `point_prompts` or `box_prompts` must be set. */
          point_prompts?: {
            /** @description X position. */
            x: number;
            /** @description Y position. */
            y: number;
          }[];
          /** @description Box prompts, to detect a segment within the bounding box. One of `point_prompts` or `box_prompts` must be set. */
          box_prompts?: {
            /**
             * Format: float
             * @description Top left corner x.
             */
            x1: number;
            /**
             * Format: float
             * @description Top left corner y.
             */
            y1: number;
            /**
             * Format: float
             * @description Bottom right corner x.
             */
            x2: number;
            /**
             * Format: float
             * @description Bottom right corner y.
             */
            y2: number;
          }[];
          /** @description Use "hosted" to return an image URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the image data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Detected segments in 'mask image' format. Base 64-encoded JPEG image bytes, or a hosted image url if `store` is provided. */
            mask_image_uri: string;
          };
        };
      };
    };
  };
  /**
   * TranscribeMedia
   * @description Transcribe speech in an audio or video file.
   */
  TranscribeMedia: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input audio. */
          audio_uri: string;
          /** @description Prompt to guide model on the content and context of input audio. */
          prompt?: string;
          /**
           * @description Language of input audio in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes) format.
           * @default en
           */
          language?: string;
          /**
           * @description Segment the text into sentences with approximate timestamps.
           * @default false
           */
          segment?: boolean;
          /**
           * @description Align transcription to produce more accurate sentence-level timestamps and word-level timestamps. An array of word segments will be included in each sentence segment.
           * @default false
           */
          align?: boolean;
          /**
           * @description Identify speakers for each segment. Speaker IDs will be included in each segment.
           * @default false
           */
          diarize?: boolean;
          /**
           * @description Suggest automatic chapter markers.
           * @default false
           */
          suggest_chapters?: boolean;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Transcribed text. */
            text: string;
            /** @description Transcribed segments, if `segment` is enabled. */
            segments?: {
              /** @description Text of segment. */
              text: string;
              /**
               * Format: float
               * @description Start time of segment, in seconds.
               */
              start: number;
              /**
               * Format: float
               * @description End time of segment, in seconds.
               */
              end: number;
              /** @description ID of speaker, if `diarize` is enabled. */
              speaker?: string;
              /** @description Aligned words, if `align` is enabled. */
              words?: {
                /** @description Text of word. */
                word: string;
                /**
                 * Format: float
                 * @description Start time of word, in seconds.
                 */
                start?: number;
                /**
                 * Format: float
                 * @description End time of word, in seconds.
                 */
                end?: number;
                /** @description ID of speaker, if `diarize` is enabled. */
                speaker?: string;
              }[];
            }[];
            /** @description Chapter markers, if `suggest_chapters` is enabled. */
            chapters?: {
              /** @description Chapter title. */
              title: string;
              /**
               * Format: float
               * @description Start time of chapter, in seconds.
               */
              start: number;
            }[];
          };
        };
      };
    };
  };
  /**
   * GenerateSpeech
   * @description Generate speech from text.
   */
  GenerateSpeech: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input text. */
          text: string;
          /** @description Use "hosted" to return an audio URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the audio data will be returned as a base64-encoded string. */
          store?: string;
          /**
           * @description Selected node.
           * @default XTTSV2
           * @enum {string}
           */
          node?: "XTTSV2";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded WAV audio bytes, or a hosted audio url if `store` is provided. */
            audio_uri: string;
          };
        };
      };
    };
  };
  /**
   * XTTSV2
   * @description Generate speech from text using [XTTS v2](https://docs.coqui.ai/en/latest/models/xtts.html).
   */
  XTTSV2: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input text. */
          text: string;
          /** @description Reference audio used to synthesize the speaker. If unset, a default speaker voice will be used. */
          audio_uri?: string;
          /**
           * @description Language of input text. Supported languages: `en, de, fr, es, it, pt, pl, zh, ar, cs, ru, nl, tr, hu, ko`.
           * @default en
           */
          language?: string;
          /** @description Use "hosted" to return an audio URL hosted on Substrate. You can also provide a URL to a registered [file store](/docs/file-stores). If unset, the audio data will be returned as a base64-encoded string. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Base 64-encoded WAV audio bytes, or a hosted audio url if `store` is provided. */
            audio_uri: string;
          };
        };
      };
    };
  };
  /**
   * EmbedText
   * @description Generate embedding for a text document.
   */
  EmbedText: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Text to embed. */
          text: string;
          /** @description [Vector store](/docs/vector-stores) identifier. */
          store?: string;
          /** @description Metadata that can be used to query the vector store. Ignored if `store` is unset. */
          metadata?: {
            [key: string]: unknown;
          };
          /** @description Choose keys from `metadata` to embed with text. */
          embedded_metadata_keys?: string[];
          /** @description Vector store document ID. Ignored if `store` is unset. */
          doc_id?: string;
          /**
           * @description Selected node.
           * @default JinaV2
           * @enum {string}
           */
          node?: "JinaV2" | "CLIP";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** Embedding */
            embedding: {
              /** @description Embedding vector. */
              vector: number[];
              /** @description Vector store document ID. */
              doc_id?: string;
              /** @description Vector store document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            };
          };
        };
      };
    };
  };
  /**
   * MultiEmbedText
   * @description Generate embeddings for multiple text documents.
   */
  MultiEmbedText: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Items to embed. */
          items: {
            /** @description Text to embed. */
            text: string;
            /** @description Metadata that can be used to query the vector store. Ignored if `store` is unset. */
            metadata?: {
              [key: string]: unknown;
            };
            /** @description Vector store document ID. Ignored if `store` is unset. */
            doc_id?: string;
          }[];
          /** @description [Vector store](/docs/vector-stores) identifier. */
          store?: string;
          /** @description Choose keys from `metadata` to embed with text. */
          embedded_metadata_keys?: string[];
          /**
           * @description Selected node.
           * @default JinaV2
           * @enum {string}
           */
          node?: "JinaV2" | "CLIP";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Generated embeddings. */
            embeddings: {
              /** @description Embedding vector. */
              vector: number[];
              /** @description Vector store document ID. */
              doc_id?: string;
              /** @description Vector store document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * EmbedImage
   * @description Generate embedding for an image.
   */
  EmbedImage: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Image to embed. */
          image_uri: string;
          /** @description [Vector store](/docs/vector-stores) identifier. */
          store?: string;
          /** @description Vector store document ID. Ignored if `store` is unset. */
          doc_id?: string;
          /**
           * @description Selected node.
           * @default CLIP
           * @enum {string}
           */
          node?: "CLIP";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** Embedding */
            embedding: {
              /** @description Embedding vector. */
              vector: number[];
              /** @description Vector store document ID. */
              doc_id?: string;
              /** @description Vector store document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            };
          };
        };
      };
    };
  };
  /**
   * MultiEmbedImage
   * @description Generate embeddings for multiple images.
   */
  MultiEmbedImage: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Items to embed. */
          items: {
            /** @description Image to embed. */
            image_uri: string;
            /** @description Vector store document ID. Ignored if `store` is unset. */
            doc_id?: string;
          }[];
          /** @description [Vector store](/docs/vector-stores) identifier. */
          store?: string;
          /**
           * @description Selected node.
           * @default CLIP
           * @enum {string}
           */
          node?: "CLIP";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Generated embeddings. */
            embeddings: {
              /** @description Embedding vector. */
              vector: number[];
              /** @description Vector store document ID. */
              doc_id?: string;
              /** @description Vector store document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * JinaV2
   * @description Generate embeddings for multiple text documents using [Jina Embeddings 2](https://arxiv.org/abs/2310.19923).
   */
  JinaV2: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Items to embed. */
          items: {
            /** @description Text to embed. */
            text: string;
            /** @description Metadata that can be used to query the vector store. Ignored if `store` is unset. */
            metadata?: {
              [key: string]: unknown;
            };
            /** @description Vector store document ID. Ignored if `store` is unset. */
            doc_id?: string;
          }[];
          /** @description [Vector store](/docs/vector-stores) identifier. */
          store?: string;
          /** @description Choose keys from `metadata` to embed with text. */
          embedded_metadata_keys?: string[];
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Generated embeddings. */
            embeddings: {
              /** @description Embedding vector. */
              vector: number[];
              /** @description Vector store document ID. */
              doc_id?: string;
              /** @description Vector store document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * CLIP
   * @description Generate embeddings for text or images using [CLIP](https://openai.com/research/clip).
   */
  CLIP: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Items to embed. */
          items: {
            /** @description Image to embed. */
            image_uri?: string;
            /** @description Text to embed. */
            text?: string;
            /** @description Metadata that can be used to query the vector store. Ignored if `store` is unset. */
            metadata?: {
              [key: string]: unknown;
            };
            /** @description Vector store document ID. Ignored if `store` is unset. */
            doc_id?: string;
          }[];
          /** @description Choose keys from `metadata` to embed with text, when embedding and storing text documents. */
          embedded_metadata_keys?: string[];
          /** @description [Vector store](/docs/vector-stores) identifier. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Generated embeddings. */
            embeddings: {
              /** @description Embedding vector. */
              vector: number[];
              /** @description Vector store document ID. */
              doc_id?: string;
              /** @description Vector store document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * CreateVectorStore
   * @description Create a vector store for storing and querying embeddings.
   */
  CreateVectorStore: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Vector store name. */
          name: string;
          /**
           * @description Selected embedding model
           * @enum {string}
           */
          model: "jina-v2" | "clip";
          /**
           * @description The max number of connections per layer for the index.
           * @default 16
           */
          m?: number;
          /**
           * @description The size of the dynamic candidate list for constructing the index graph.
           * @default 64
           */
          ef_construction?: number;
          /**
           * @description The distance metric to construct the index with.
           * @default inner
           * @enum {string}
           */
          metric?: "cosine" | "l2" | "inner";
        };
      };
    };
    responses: {
      /** @description Vector store created. */
      200: {
        content: {
          "application/json": {
            /** @description Vector store name. */
            name: string;
            /**
             * @description Selected embedding model
             * @enum {string}
             */
            model: "jina-v2" | "clip";
            /**
             * @description The max number of connections per layer for the index.
             * @default 16
             */
            m: number;
            /**
             * @description The size of the dynamic candidate list for constructing the index graph.
             * @default 64
             */
            ef_construction: number;
            /**
             * @description The distance metric to construct the index with.
             * @default inner
             * @enum {string}
             */
            metric: "cosine" | "l2" | "inner";
          };
        };
      };
    };
  };
  /**
   * ListVectorStores
   * @description List all vector stores.
   */
  ListVectorStores: {
    parameters: {
      query?: {
        undefined?: Record<string, never>;
      };
    };
    responses: {
      /** @description List of vector stores. */
      200: {
        content: {
          "application/json": {
            /** @description List of vector stores. */
            stores?: {
              /** @description Vector store name. */
              name: string;
              /**
               * @description Selected embedding model
               * @enum {string}
               */
              model: "jina-v2" | "clip";
              /**
               * @description The max number of connections per layer for the index.
               * @default 16
               */
              m: number;
              /**
               * @description The size of the dynamic candidate list for constructing the index graph.
               * @default 64
               */
              ef_construction: number;
              /**
               * @description The distance metric to construct the index with.
               * @default inner
               * @enum {string}
               */
              metric: "cosine" | "l2" | "inner";
            }[];
          };
        };
      };
    };
  };
  /**
   * DeleteVectorStore
   * @description Delete a vector store.
   */
  DeleteVectorStore: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Vector store name. */
          name: string;
          /**
           * @description Selected embedding model
           * @enum {string}
           */
          model: "jina-v2" | "clip";
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** @description Vector store name. */
            name: string;
            /**
             * @description Selected embedding model
             * @enum {string}
             */
            model: "jina-v2" | "clip";
          };
        };
      };
    };
  };
  /**
   * QueryVectorStore
   * @description Query a vector store for similar vectors.
   */
  QueryVectorStore: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Vector store to query against. */
          name: string;
          /**
           * @description Selected embedding model
           * @enum {string}
           */
          model: "jina-v2" | "clip";
          /** @description Document IDs to use for the query. */
          query_ids?: string[];
          /** @description Image URIs to embed and use for the query. */
          query_image_uris?: string[];
          /** @description Vector to use for the query. */
          query_vectors?: number[][];
          /** @description Texts to embed and use for the query. */
          query_strings?: string[];
          /**
           * @description Number of results to return.
           * @default 10
           */
          top_k?: number;
          /**
           * @description The size of the dynamic candidate list for searching the index graph.
           * @default 40
           */
          ef_search?: number;
          /**
           * @description Include the values of the vectors in the response.
           * @default false
           */
          include_values?: boolean;
          /**
           * @description Include the metadata of the vectors in the response.
           * @default false
           */
          include_metadata?: boolean;
          /** @description Filter metadata by key-value pairs. */
          filters?: {
            [key: string]: unknown;
          };
          /**
           * @description The distance metric used for the query. Defaults to the distance metric the vector store was created with.
           * @enum {string}
           */
          metric?: "cosine" | "l2" | "inner";
        };
      };
    };
    responses: {
      /** @description Query results. */
      200: {
        content: {
          "application/json": {
            /** @description Query results. */
            results: {
              /** @description Document ID. */
              id: string;
              /**
               * Format: float
               * @description Similarity score.
               */
              distance: number;
              /** @description Embedding vector. */
              vector?: number[];
              /** @description Document metadata. */
              metadata?: {
                [key: string]: unknown;
              };
            }[][];
            /** @description Vector store name. */
            name?: string;
            /**
             * @description Selected embedding model
             * @enum {string}
             */
            model?: "jina-v2" | "clip";
            /**
             * @description The distance metric used for the query.
             * @enum {string}
             */
            metric?: "cosine" | "l2" | "inner";
          };
        };
      };
    };
  };
  /**
   * FetchVectors
   * @description Fetch vectors from a vector store.
   */
  FetchVectors: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Vector store name. */
          name: string;
          /**
           * @description Selected embedding model
           * @enum {string}
           */
          model: "jina-v2" | "clip";
          /** @description Document IDs to retrieve. */
          ids: string[];
        };
      };
    };
    responses: {
      /** @description Vector data. */
      200: {
        content: {
          "application/json": {
            /** @description Retrieved vectors. */
            vectors: {
              /** @description Document ID. */
              id: string;
              /** @description Embedding vector. */
              vector: number[];
              /** @description Document metadata. */
              metadata: {
                [key: string]: unknown;
              };
            }[];
          };
        };
      };
    };
  };
  /**
   * UpdateVectors
   * @description Update vectors in a vector store.
   */
  UpdateVectors: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Vector store name. */
          name: string;
          /**
           * @description Selected embedding model
           * @enum {string}
           */
          model: "jina-v2" | "clip";
          /** @description Vectors to upsert. */
          vectors: {
            /** @description Document ID. */
            id: string;
            /** @description Embedding vector. */
            vector?: number[];
            /** @description Document metadata. */
            metadata?: {
              [key: string]: unknown;
            };
          }[];
        };
      };
    };
    responses: {
      /** @description Count of updated vectors. */
      200: {
        content: {
          "application/json": {
            /** @description Number of vectors modified. */
            count: number;
          };
        };
      };
    };
  };
  /**
   * DeleteVectors
   * @description Delete vectors in a vector store.
   */
  DeleteVectors: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Vector store name. */
          name: string;
          /**
           * @description Selected embedding model
           * @enum {string}
           */
          model: "jina-v2" | "clip";
          /** @description Document IDs to delete. */
          ids: string[];
        };
      };
    };
    responses: {
      /** @description Count of deleted vectors. */
      200: {
        content: {
          "application/json": {
            /** @description Number of vectors modified. */
            count: number;
          };
        };
      };
    };
  };
}
