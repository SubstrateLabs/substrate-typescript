// Generated by ts-to-zod
import { z } from "zod";
import { components } from "./OpenAPI";

export const componentsSchema: z.ZodSchema<components> = z.lazy(() =>
  z.object({
    schemas: z.object({
      ErrorOut: z.object({
        type: z
          .union([z.literal("api_error"), z.literal("invalid_request_error")])
          .describe("The type of error returned."),
        message: z
          .string()
          .describe("A message providing more details about the error."),
      }),
      StableDiffusionInputImage: z.object({
        image_url: z
          .string()
          .describe("Input image URL to modify with a text prompt."),
        mask_image_url: z
          .string()
          .optional()
          .describe("Mask of the input image to selectively modify."),
        prompt_strength: z
          .number()
          .optional()
          .describe(
            "Controls the influence of the input prompt on the generated output.",
          )
          .default(0),
      }),
      StableDiffusionIn: z.object({
        prompt: z.string().describe("Input prompt."),
        negative_prompt: z
          .string()
          .optional()
          .describe("Negative input prompt."),
        image: componentsSchema.shape.schemas.shape.StableDiffusionInputImage,
        store: z
          .boolean()
          .optional()
          .describe(
            "Return a hosted image URL instead of base64 encoded image data.",
          )
          .default(false),
        width: z
          .number()
          .optional()
          .describe("Width of output image, in pixels."),
        height: z
          .number()
          .optional()
          .describe("Height of output image, in pixels."),
        steps: z
          .number()
          .optional()
          .describe("Number of diffusion steps to run."),
        seed: z
          .number()
          .optional()
          .describe("Random noise seed. Default is a random seed."),
        guidance_scale: z
          .number()
          .optional()
          .describe(
            "Controls the influence of the input prompt on the generated output.",
          ),
        num_images: z
          .number()
          .optional()
          .describe("Number of images to generate.")
          .default(1),
      }),
      StableDiffusionImage: z.object({
        uri: z
          .string()
          .describe(
            "Base 64-encoded JPEG image bytes, or a hosted image url if `store` is enabled.",
          ),
        seed: z.number().describe("The random noise seed used for generation."),
      }),
      StableDiffusionOut: z.array(
        componentsSchema.shape.schemas.shape.StableDiffusionImage,
      ),
      StableDiffusionResponse: z.object({
        data: componentsSchema.shape.schemas.shape.StableDiffusionOut,
        error: componentsSchema.shape.schemas.shape.ErrorOut,
      }),
      MistralPrompt: z.object({
        prompt: z.string().describe("Prompt to generate completions for."),
      }),
      MistralIn: z.object({
        prompts: z
          .array(componentsSchema.shape.schemas.shape.MistralPrompt)
          .describe("Input prompts."),
        temperature: z
          .number()
          .optional()
          .describe(
            "Sampling temperature to use. Higher values make the output more random; lower values make the output more deterministic.",
          )
          .default(0),
        max_tokens: z
          .number()
          .optional()
          .describe("Maximum number of tokens to generate.")
          .default(800),
        num_completions: z
          .number()
          .optional()
          .describe("Number of completions to generate for each prompt.")
          .default(1),
      }),
      MistralResult: z.object({
        completions: z
          .array(z.string())
          .describe("Generated completion choices."),
      }),
      MistralOut: z.array(componentsSchema.shape.schemas.shape.MistralResult),
      MistralResponse: z.object({
        data: componentsSchema.shape.schemas.shape.MistralOut,
        error: componentsSchema.shape.schemas.shape.ErrorOut,
      }),
      WhisperIn: z.object({
        audio_url: z.string().describe("Input audio URL."),
        prompt: z
          .string()
          .optional()
          .describe(
            "Prompt to guide model on contents of input audio and desired output.",
          ),
        language: z
          .string()
          .optional()
          .describe("Language of input audio in ISO-639-1 format.")
          .default("en"),
        align: z
          .boolean()
          .optional()
          .describe(
            "Align transcription to produce more accurate sentence-level timestamps and word-level timestamps. An array of word segments will be included in each sentence segment.",
          )
          .default(false),
        diarize: z
          .boolean()
          .optional()
          .describe(
            "Identify speakers for each segment. Speaker IDs will be added to each output segment.",
          )
          .default(false),
      }),
      WhisperWord: z.object({
        word: z.string().describe("Text of word."),
        start: z.number().describe("Start time of word, in seconds."),
        end: z.number().describe("End time of word, in seconds."),
        speaker: z
          .string()
          .optional()
          .describe("ID of speaker, if `diarize` is enabled."),
      }),
      WhisperSegment: z.object({
        text: z.string().describe("Text of segment."),
        start: z.number().describe("Start time of segment, in seconds."),
        end: z.number().describe("End time of segment, in seconds."),
        speaker: z
          .string()
          .optional()
          .describe("ID of speaker, if `diarize` is enabled."),
        words: z
          .array(componentsSchema.shape.schemas.shape.WhisperWord)
          .optional()
          .describe("Aligned words, if `align` is enabled."),
      }),
      WhisperOut: z.array(componentsSchema.shape.schemas.shape.WhisperSegment),
      WhisperResponse: z.object({
        data: componentsSchema.shape.schemas.shape.WhisperOut,
        error: componentsSchema.shape.schemas.shape.ErrorOut,
      }),
      JinaDoc: z.object({
        text: z.string().describe("Text to embed."),
        id: z
          .string()
          .optional()
          .describe("Document id. Required when storing embedding."),
        metadata: z
          .record(
            z
              .never()
              .describe("Additional metadata to store in embedding document."),
          )
          .optional()
          .describe("Additional metadata to store in embedding document."),
        embed_metadata_keys: z
          .array(z.string())
          .optional()
          .describe("Contents of `metadata` included to generate embedding."),
      }),
      JinaIn: z.object({
        docs: z
          .array(componentsSchema.shape.schemas.shape.JinaDoc)
          .describe("Documents to embed."),
        store: z
          .string()
          .optional()
          .describe("Vector store ID in which embedding will be stored."),
      }),
      JinaEmbedding: z.object({
        vector: z.string().describe("Embedding vector."),
        id: z.string().optional().describe("Document id."),
        metadata: z
          .record(
            z
              .never()
              .describe("Additional metadata stored in embedding document."),
          )
          .optional()
          .describe("Additional metadata stored in embedding document."),
      }),
      JinaOut: z.array(componentsSchema.shape.schemas.shape.JinaEmbedding),
      JinaResponse: z.object({
        data: componentsSchema.shape.schemas.shape.JinaOut,
        error: componentsSchema.shape.schemas.shape.ErrorOut,
      }),
      CLIPDoc: z.object({
        text: z.string().optional().describe("Text to embed."),
        image_url: z.string().optional().describe("URL of image to embed."),
        id: z
          .string()
          .optional()
          .describe("Document id. Required when storing embedding."),
        metadata: z
          .record(
            z
              .never()
              .describe("Additional metadata to store in embedding document."),
          )
          .optional()
          .describe("Additional metadata to store in embedding document."),
        embed_metadata_keys: z
          .array(z.string())
          .optional()
          .describe("Contents of `metadata` included to generate embedding."),
      }),
      CLIPIn: z.object({
        docs: z
          .array(componentsSchema.shape.schemas.shape.CLIPDoc)
          .describe("Documents to embed."),
        store: z
          .string()
          .optional()
          .describe("Vector store ID in which embedding will be stored."),
      }),
      CLIPEmbedding: z.object({
        vector: z.string().describe("Embedding vector."),
        id: z.string().optional().describe("Document id."),
        metadata: z
          .record(
            z
              .never()
              .describe("Additional metadata stored in embedding document."),
          )
          .optional()
          .describe("Additional metadata stored in embedding document."),
      }),
      CLIPOut: z.array(componentsSchema.shape.schemas.shape.CLIPEmbedding),
      CLIPResponse: z.object({
        data: componentsSchema.shape.schemas.shape.CLIPOut,
        error: componentsSchema.shape.schemas.shape.ErrorOut,
      }),
    }),
    responses: z.never(),
    parameters: z.never(),
    requestBodies: z.never(),
    headers: z.never(),
    pathItems: z.never(),
  }),
);
