/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */


export interface paths {
  "/stablediffusion": {
    /**
     * StableDiffusion
     * @description Generate an image from a text prompt using the Stable Diffusion family of image models. Trained by [Stability AI](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl) and hosted on Substrate.
     */
    post: operations["StableDiffusion"];
  };
  "/mistral": {
    /**
     * Mistral
     * @description Generate text using the Mistral family of language models. Trained by [Mistral AI](https://huggingface.co/docs/transformers/main/model_doc/mistral) and hosted on Substrate.
     */
    post: operations["Mistral"];
  };
  "/whisper": {
    /**
     * Whisper
     * @description Transcribe audio using the Whisper family of models. Includes sentence-level segmentation, word-level alignment and speaker diarization. Trained by [Open AI](https://huggingface.co/docs/transformers/model_doc/whisper) and hosted on Substrate.
     */
    post: operations["Whisper"];
  };
  "/jina": {
    /**
     * Jina
     * @description TODO. Trained by [Jina AI](https://huggingface.co/jinaai) and hosted on Substrate.
     */
    post: operations["Jina"];
  };
  "/clip": {
    /**
     * CLIP
     * @description TODO. Trained by [Open AI](https://huggingface.co/docs/transformers/model_doc/clip) and hosted on Substrate.
     */
    post: operations["CLIP"];
  };
}

export type webhooks = Record<string, never>;

export interface components {
  schemas: {
    /** ErrorOut */
    ErrorOut: {
      /**
       * @description The type of error returned.
       * @enum {string}
       */
      type: "api_error" | "invalid_request_error";
      /** @description A message providing more details about the error. */
      message: string;
    };
    /** StableDiffusionInputImage */
    StableDiffusionInputImage: {
      /** @description Input image URL to modify with a text prompt. */
      image_url: string;
      /** @description Mask of the input image to selectively modify. */
      mask_image_url?: string;
      /**
       * Format: float
       * @description Controls the influence of the input prompt on the generated output.
       * @default 0.6
       */
      prompt_strength?: number;
    };
    /** StableDiffusionIn */
    StableDiffusionIn: {
      /** @description Input prompt. */
      prompt: string;
      /** @description Negative input prompt. */
      negative_prompt?: string;
      /** @description Image parameters to modify an existing image (image-to-image). */
      image?: components["schemas"]["StableDiffusionInputImage"];
      /**
       * @description Return a hosted image URL instead of base64 encoded image data.
       * @default false
       */
      store?: boolean;
      /** @description Width of output image, in pixels. */
      width?: number;
      /** @description Height of output image, in pixels. */
      height?: number;
      /** @description Number of diffusion steps to run. */
      steps?: number;
      /** @description Random noise seed. Default is a random seed. */
      seed?: number;
      /** @description Controls the influence of the input prompt on the generated output. */
      guidance_scale?: number;
      /**
       * @description Number of images to generate.
       * @default 1
       */
      num_images?: number;
    };
    /** StableDiffusionImage */
    StableDiffusionImage: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is enabled. */
      uri: string;
      /** @description The random noise seed used for generation. */
      seed: number;
    };
    /** StableDiffusionOut */
    StableDiffusionOut: components["schemas"]["StableDiffusionImage"][];
    /** StableDiffusionResponse */
    StableDiffusionResponse: {
      data?: components["schemas"]["StableDiffusionOut"];
      error?: components["schemas"]["ErrorOut"];
    };
    /** MistralPrompt */
    MistralPrompt: {
      /** @description Prompt to generate completions for. */
      prompt: string;
    };
    /** MistralIn */
    MistralIn: {
      /** @description Input prompts. */
      prompts: components["schemas"]["MistralPrompt"][];
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random; lower values make the output more deterministic.
       * @default 0.75
       */
      temperature?: number;
      /**
       * @description Maximum number of tokens to generate.
       * @default 800
       */
      max_tokens?: number;
      /**
       * @description Number of completions to generate for each prompt.
       * @default 1
       */
      num_completions?: number;
    };
    /** MistralResult */
    MistralResult: {
      /** @description Generated completion choices. */
      completions: string[];
    };
    /** MistralOut */
    MistralOut: components["schemas"]["MistralResult"][];
    /** MistralResponse */
    MistralResponse: {
      data?: components["schemas"]["MistralOut"];
      error?: components["schemas"]["ErrorOut"];
    };
    /** WhisperIn */
    WhisperIn: {
      /** @description Input audio URL. */
      audio_url: string;
      /** @description Prompt to guide model on contents of input audio and desired output. */
      prompt?: string;
      /**
       * @description Language of input audio in ISO-639-1 format.
       * @default en
       */
      language?: string;
      /**
       * @description Align transcription to produce more accurate sentence-level timestamps and word-level timestamps. An array of word segments will be included in each sentence segment.
       * @default false
       */
      align?: boolean;
      /**
       * @description Identify speakers for each segment. Speaker IDs will be added to each output segment.
       * @default false
       */
      diarize?: boolean;
    };
    /** WhisperWord */
    WhisperWord: {
      /** @description Text of word. */
      word: string;
      /**
       * Format: float
       * @description Start time of word, in seconds.
       */
      start: number;
      /**
       * Format: float
       * @description End time of word, in seconds.
       */
      end: number;
      /** @description ID of speaker, if `diarize` is enabled. */
      speaker?: string;
    };
    /** WhisperSegment */
    WhisperSegment: {
      /** @description Text of segment. */
      text: string;
      /**
       * Format: float
       * @description Start time of segment, in seconds.
       */
      start: number;
      /**
       * Format: float
       * @description End time of segment, in seconds.
       */
      end: number;
      /** @description ID of speaker, if `diarize` is enabled. */
      speaker?: string;
      /** @description Aligned words, if `align` is enabled. */
      words?: components["schemas"]["WhisperWord"][];
    };
    /** WhisperOut */
    WhisperOut: components["schemas"]["WhisperSegment"][];
    /** WhisperResponse */
    WhisperResponse: {
      data?: components["schemas"]["WhisperOut"];
      error?: components["schemas"]["ErrorOut"];
    };
    /** JinaDoc */
    JinaDoc: {
      /** @description Text to embed. */
      text: string;
      /** @description Document id. Required when storing embedding. */
      id?: string;
      /** @description Additional metadata to store in embedding document. */
      metadata?: Record<string, never>;
      /** @description Contents of `metadata` included to generate embedding. */
      embed_metadata_keys?: string[];
    };
    /** JinaIn */
    JinaIn: {
      /** @description Documents to embed. */
      docs: components["schemas"]["JinaDoc"][];
      /** @description Vector store ID in which embedding will be stored. */
      store?: string;
    };
    /** JinaEmbedding */
    JinaEmbedding: {
      /** @description Embedding vector. */
      vector: string;
      /** @description Document id. */
      id?: string;
      /** @description Additional metadata stored in embedding document. */
      metadata?: Record<string, never>;
    };
    /** JinaOut */
    JinaOut: components["schemas"]["JinaEmbedding"][];
    /** JinaResponse */
    JinaResponse: {
      data?: components["schemas"]["JinaOut"];
      error?: components["schemas"]["ErrorOut"];
    };
    /** CLIPDoc */
    CLIPDoc: {
      /** @description Text to embed. */
      text?: string;
      /** @description URL of image to embed. */
      image_url?: string;
      /** @description Document id. Required when storing embedding. */
      id?: string;
      /** @description Additional metadata to store in embedding document. */
      metadata?: Record<string, never>;
      /** @description Contents of `metadata` included to generate embedding. */
      embed_metadata_keys?: string[];
    };
    /** CLIPIn */
    CLIPIn: {
      /** @description Documents to embed. */
      docs: components["schemas"]["CLIPDoc"][];
      /** @description Vector store ID in which embedding will be stored. */
      store?: string;
    };
    /** CLIPEmbedding */
    CLIPEmbedding: {
      /** @description Embedding vector. */
      vector: string;
      /** @description Document id. */
      id?: string;
      /** @description Additional metadata stored in embedding document. */
      metadata?: Record<string, never>;
    };
    /** CLIPOut */
    CLIPOut: components["schemas"]["CLIPEmbedding"][];
    /** CLIPResponse */
    CLIPResponse: {
      data?: components["schemas"]["CLIPOut"];
      error?: components["schemas"]["ErrorOut"];
    };
  };
  responses: never;
  parameters: never;
  requestBodies: never;
  headers: never;
  pathItems: never;
}

export type $defs = Record<string, never>;

export type external = Record<string, never>;

export interface operations {

  /**
   * StableDiffusion
   * @description Generate an image from a text prompt using the Stable Diffusion family of image models. Trained by [Stability AI](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl) and hosted on Substrate.
   */
  StableDiffusion: {
    parameters: {
      query?: {
        undefined?: components["schemas"]["StableDiffusionIn"];
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": components["schemas"]["StableDiffusionResponse"];
        };
      };
    };
  };
  /**
   * Mistral
   * @description Generate text using the Mistral family of language models. Trained by [Mistral AI](https://huggingface.co/docs/transformers/main/model_doc/mistral) and hosted on Substrate.
   */
  Mistral: {
    parameters: {
      query?: {
        undefined?: components["schemas"]["MistralIn"];
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": components["schemas"]["MistralResponse"];
        };
      };
    };
  };
  /**
   * Whisper
   * @description Transcribe audio using the Whisper family of models. Includes sentence-level segmentation, word-level alignment and speaker diarization. Trained by [Open AI](https://huggingface.co/docs/transformers/model_doc/whisper) and hosted on Substrate.
   */
  Whisper: {
    parameters: {
      query?: {
        undefined?: components["schemas"]["WhisperIn"];
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": components["schemas"]["WhisperResponse"];
        };
      };
    };
  };
  /**
   * Jina
   * @description TODO. Trained by [Jina AI](https://huggingface.co/jinaai) and hosted on Substrate.
   */
  Jina: {
    parameters: {
      query?: {
        undefined?: components["schemas"]["JinaIn"];
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": components["schemas"]["JinaResponse"];
        };
      };
    };
  };
  /**
   * CLIP
   * @description TODO. Trained by [Open AI](https://huggingface.co/docs/transformers/model_doc/clip) and hosted on Substrate.
   */
  CLIP: {
    parameters: {
      query?: {
        undefined?: components["schemas"]["CLIPIn"];
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": components["schemas"]["CLIPResponse"];
        };
      };
    };
  };
}
