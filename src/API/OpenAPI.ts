/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */


export interface paths {
  "/stablediffusion": {
    /**
     * StableDiffusion
     * @description Generate an image from a text prompt using the Stable Diffusion family of image models. Trained by [Stability AI](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl) and hosted on Substrate.
     */
    post: operations["StableDiffusion"];
  };
  "/mistral": {
    /**
     * Mistral
     * @description Generate text using the Mistral family of language models. Trained by [Mistral AI](https://huggingface.co/docs/transformers/main/model_doc/mistral) and hosted on Substrate.
     */
    post: operations["Mistral"];
  };
  "/whisper": {
    /**
     * Whisper
     * @description Transcribe audio using the Whisper family of models. Includes sentence-level segmentation, word-level alignment and speaker diarization. Trained by [Open AI](https://huggingface.co/docs/transformers/model_doc/whisper) and hosted on Substrate.
     */
    post: operations["Whisper"];
  };
  "/jina": {
    /**
     * Jina
     * @description TODO. Trained by [Jina AI](https://huggingface.co/jinaai) and hosted on Substrate.
     */
    post: operations["Jina"];
  };
  "/clip": {
    /**
     * CLIP
     * @description TODO. Trained by [Open AI](https://huggingface.co/docs/transformers/model_doc/clip) and hosted on Substrate.
     */
    post: operations["CLIP"];
  };
}

export type webhooks = Record<string, never>;

export interface components {
  schemas: {
    /** ErrorOut */
    ErrorOut: {
      /**
       * @description The type of error returned.
       * @enum {string}
       */
      type: "api_error" | "invalid_request_error";
      /** @description A message providing more details about the error. */
      message: string;
    };
    /** StableDiffusionInputImage */
    StableDiffusionInputImage: {
      /** @description Input image URL to modify with a text prompt. */
      image_url: string;
      /** @description Mask of the input image to selectively modify. */
      mask_image_url?: string;
      /**
       * Format: float
       * @description Controls the influence of the input prompt on the generated output.
       * @default 0.6
       */
      prompt_strength?: number;
    };
    /** StableDiffusionIn */
    StableDiffusionIn: {
      /** @description Input prompt. */
      prompt: string;
      /** @description Negative input prompt. */
      negative_prompt?: string;
      /** StableDiffusionInputImage */
      image?: {
        /** @description Input image URL to modify with a text prompt. */
        image_url: string;
        /** @description Mask of the input image to selectively modify. */
        mask_image_url?: string;
        /**
         * Format: float
         * @description Controls the influence of the input prompt on the generated output.
         * @default 0.6
         */
        prompt_strength?: number;
      };
      /**
       * @description Return a hosted image URL instead of base64 encoded image data.
       * @default false
       */
      store?: boolean;
      /** @description Width of output image, in pixels. */
      width?: number;
      /** @description Height of output image, in pixels. */
      height?: number;
      /** @description Number of diffusion steps to run. */
      steps?: number;
      /** @description Random noise seed. Default is a random seed. */
      seed?: number;
      /** @description Controls the influence of the input prompt on the generated output. */
      guidance_scale?: number;
      /**
       * @description Number of images to generate.
       * @default 1
       */
      num_images?: number;
    };
    /** StableDiffusionImage */
    StableDiffusionImage: {
      /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is enabled. */
      uri: string;
      /** @description The random noise seed used for generation. */
      seed: number;
    };
    /** StableDiffusionOut */
    StableDiffusionOut: {
        /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is enabled. */
        uri: string;
        /** @description The random noise seed used for generation. */
        seed: number;
      }[];
    /** StableDiffusionResponse */
    StableDiffusionResponse: {
      /** StableDiffusionOut */
      data?: {
          /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is enabled. */
          uri: string;
          /** @description The random noise seed used for generation. */
          seed: number;
        }[];
      /** ErrorOut */
      error?: {
        /**
         * @description The type of error returned.
         * @enum {string}
         */
        type: "api_error" | "invalid_request_error";
        /** @description A message providing more details about the error. */
        message: string;
      };
    };
    /** MistralPrompt */
    MistralPrompt: {
      /** @description Prompt to generate completions for. */
      prompt: string;
    };
    /** MistralIn */
    MistralIn: {
      /** @description Input prompts. */
      prompts: {
          /** @description Prompt to generate completions for. */
          prompt: string;
        }[];
      /**
       * Format: float
       * @description Sampling temperature to use. Higher values make the output more random; lower values make the output more deterministic.
       * @default 0.75
       */
      temperature?: number;
      /**
       * @description Maximum number of tokens to generate.
       * @default 800
       */
      max_tokens?: number;
      /**
       * @description Number of completions to generate for each prompt.
       * @default 1
       */
      num_completions?: number;
    };
    /** MistralResult */
    MistralResult: {
      /** @description Generated completion choices. */
      completions: string[];
    };
    /** MistralOut */
    MistralOut: {
        /** @description Generated completion choices. */
        completions: string[];
      }[];
    /** MistralResponse */
    MistralResponse: {
      /** MistralOut */
      data?: {
          /** @description Generated completion choices. */
          completions: string[];
        }[];
      /** ErrorOut */
      error?: {
        /**
         * @description The type of error returned.
         * @enum {string}
         */
        type: "api_error" | "invalid_request_error";
        /** @description A message providing more details about the error. */
        message: string;
      };
    };
    /** WhisperIn */
    WhisperIn: {
      /** @description Input audio URL. */
      audio_url: string;
      /** @description Prompt to guide model on contents of input audio and desired output. */
      prompt?: string;
      /**
       * @description Language of input audio in ISO-639-1 format.
       * @default en
       */
      language?: string;
      /**
       * @description Align transcription to produce more accurate sentence-level timestamps and word-level timestamps. An array of word segments will be included in each sentence segment.
       * @default false
       */
      align?: boolean;
      /**
       * @description Identify speakers for each segment. Speaker IDs will be added to each output segment.
       * @default false
       */
      diarize?: boolean;
    };
    /** WhisperWord */
    WhisperWord: {
      /** @description Text of word. */
      word: string;
      /**
       * Format: float
       * @description Start time of word, in seconds.
       */
      start: number;
      /**
       * Format: float
       * @description End time of word, in seconds.
       */
      end: number;
      /** @description ID of speaker, if `diarize` is enabled. */
      speaker?: string;
    };
    /** WhisperSegment */
    WhisperSegment: {
      /** @description Text of segment. */
      text: string;
      /**
       * Format: float
       * @description Start time of segment, in seconds.
       */
      start: number;
      /**
       * Format: float
       * @description End time of segment, in seconds.
       */
      end: number;
      /** @description ID of speaker, if `diarize` is enabled. */
      speaker?: string;
      /** @description Aligned words, if `align` is enabled. */
      words?: {
          /** @description Text of word. */
          word: string;
          /**
           * Format: float
           * @description Start time of word, in seconds.
           */
          start: number;
          /**
           * Format: float
           * @description End time of word, in seconds.
           */
          end: number;
          /** @description ID of speaker, if `diarize` is enabled. */
          speaker?: string;
        }[];
    };
    /** WhisperOut */
    WhisperOut: {
        /** @description Text of segment. */
        text: string;
        /**
         * Format: float
         * @description Start time of segment, in seconds.
         */
        start: number;
        /**
         * Format: float
         * @description End time of segment, in seconds.
         */
        end: number;
        /** @description ID of speaker, if `diarize` is enabled. */
        speaker?: string;
        /** @description Aligned words, if `align` is enabled. */
        words?: {
            /** @description Text of word. */
            word: string;
            /**
             * Format: float
             * @description Start time of word, in seconds.
             */
            start: number;
            /**
             * Format: float
             * @description End time of word, in seconds.
             */
            end: number;
            /** @description ID of speaker, if `diarize` is enabled. */
            speaker?: string;
          }[];
      }[];
    /** WhisperResponse */
    WhisperResponse: {
      /** WhisperOut */
      data?: {
          /** @description Text of segment. */
          text: string;
          /**
           * Format: float
           * @description Start time of segment, in seconds.
           */
          start: number;
          /**
           * Format: float
           * @description End time of segment, in seconds.
           */
          end: number;
          /** @description ID of speaker, if `diarize` is enabled. */
          speaker?: string;
          /** @description Aligned words, if `align` is enabled. */
          words?: {
              /** @description Text of word. */
              word: string;
              /**
               * Format: float
               * @description Start time of word, in seconds.
               */
              start: number;
              /**
               * Format: float
               * @description End time of word, in seconds.
               */
              end: number;
              /** @description ID of speaker, if `diarize` is enabled. */
              speaker?: string;
            }[];
        }[];
      /** ErrorOut */
      error?: {
        /**
         * @description The type of error returned.
         * @enum {string}
         */
        type: "api_error" | "invalid_request_error";
        /** @description A message providing more details about the error. */
        message: string;
      };
    };
    /** JinaDoc */
    JinaDoc: {
      /** @description Text to embed. */
      text: string;
      /** @description Document id. Required when storing embedding. */
      id?: string;
      /** @description Additional metadata to store in embedding document. */
      metadata?: Record<string, never>;
      /** @description Contents of `metadata` included to generate embedding. */
      embed_metadata_keys?: string[];
    };
    /** JinaIn */
    JinaIn: {
      /** @description Documents to embed. */
      docs: {
          /** @description Text to embed. */
          text: string;
          /** @description Document id. Required when storing embedding. */
          id?: string;
          /** @description Additional metadata to store in embedding document. */
          metadata?: Record<string, never>;
          /** @description Contents of `metadata` included to generate embedding. */
          embed_metadata_keys?: string[];
        }[];
      /** @description Vector store ID in which embedding will be stored. */
      store?: string;
    };
    /** JinaEmbedding */
    JinaEmbedding: {
      /** @description Embedding vector. */
      vector: string;
      /** @description Document id. */
      id?: string;
      /** @description Additional metadata stored in embedding document. */
      metadata?: Record<string, never>;
    };
    /** JinaOut */
    JinaOut: {
        /** @description Embedding vector. */
        vector: string;
        /** @description Document id. */
        id?: string;
        /** @description Additional metadata stored in embedding document. */
        metadata?: Record<string, never>;
      }[];
    /** JinaResponse */
    JinaResponse: {
      /** JinaOut */
      data?: {
          /** @description Embedding vector. */
          vector: string;
          /** @description Document id. */
          id?: string;
          /** @description Additional metadata stored in embedding document. */
          metadata?: Record<string, never>;
        }[];
      /** ErrorOut */
      error?: {
        /**
         * @description The type of error returned.
         * @enum {string}
         */
        type: "api_error" | "invalid_request_error";
        /** @description A message providing more details about the error. */
        message: string;
      };
    };
    /** CLIPDoc */
    CLIPDoc: {
      /** @description Text to embed. */
      text?: string;
      /** @description URL of image to embed. */
      image_url?: string;
      /** @description Document id. Required when storing embedding. */
      id?: string;
      /** @description Additional metadata to store in embedding document. */
      metadata?: Record<string, never>;
      /** @description Contents of `metadata` included to generate embedding. */
      embed_metadata_keys?: string[];
    };
    /** CLIPIn */
    CLIPIn: {
      /** @description Documents to embed. */
      docs: {
          /** @description Text to embed. */
          text?: string;
          /** @description URL of image to embed. */
          image_url?: string;
          /** @description Document id. Required when storing embedding. */
          id?: string;
          /** @description Additional metadata to store in embedding document. */
          metadata?: Record<string, never>;
          /** @description Contents of `metadata` included to generate embedding. */
          embed_metadata_keys?: string[];
        }[];
      /** @description Vector store ID in which embedding will be stored. */
      store?: string;
    };
    /** CLIPEmbedding */
    CLIPEmbedding: {
      /** @description Embedding vector. */
      vector: string;
      /** @description Document id. */
      id?: string;
      /** @description Additional metadata stored in embedding document. */
      metadata?: Record<string, never>;
    };
    /** CLIPOut */
    CLIPOut: {
        /** @description Embedding vector. */
        vector: string;
        /** @description Document id. */
        id?: string;
        /** @description Additional metadata stored in embedding document. */
        metadata?: Record<string, never>;
      }[];
    /** CLIPResponse */
    CLIPResponse: {
      /** CLIPOut */
      data?: {
          /** @description Embedding vector. */
          vector: string;
          /** @description Document id. */
          id?: string;
          /** @description Additional metadata stored in embedding document. */
          metadata?: Record<string, never>;
        }[];
      /** ErrorOut */
      error?: {
        /**
         * @description The type of error returned.
         * @enum {string}
         */
        type: "api_error" | "invalid_request_error";
        /** @description A message providing more details about the error. */
        message: string;
      };
    };
  };
  responses: never;
  parameters: never;
  requestBodies: never;
  headers: never;
  pathItems: never;
}

export type $defs = Record<string, never>;

export type external = Record<string, never>;

export interface operations {

  /**
   * StableDiffusion
   * @description Generate an image from a text prompt using the Stable Diffusion family of image models. Trained by [Stability AI](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl) and hosted on Substrate.
   */
  StableDiffusion: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input prompt. */
          prompt: string;
          /** @description Negative input prompt. */
          negative_prompt?: string;
          /** StableDiffusionInputImage */
          image?: {
            /** @description Input image URL to modify with a text prompt. */
            image_url: string;
            /** @description Mask of the input image to selectively modify. */
            mask_image_url?: string;
            /**
             * Format: float
             * @description Controls the influence of the input prompt on the generated output.
             * @default 0.6
             */
            prompt_strength?: number;
          };
          /**
           * @description Return a hosted image URL instead of base64 encoded image data.
           * @default false
           */
          store?: boolean;
          /** @description Width of output image, in pixels. */
          width?: number;
          /** @description Height of output image, in pixels. */
          height?: number;
          /** @description Number of diffusion steps to run. */
          steps?: number;
          /** @description Random noise seed. Default is a random seed. */
          seed?: number;
          /** @description Controls the influence of the input prompt on the generated output. */
          guidance_scale?: number;
          /**
           * @description Number of images to generate.
           * @default 1
           */
          num_images?: number;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** StableDiffusionOut */
            data?: {
                /** @description Base 64-encoded JPEG image bytes, or a hosted image url if `store` is enabled. */
                uri: string;
                /** @description The random noise seed used for generation. */
                seed: number;
              }[];
            /** ErrorOut */
            error?: {
              /**
               * @description The type of error returned.
               * @enum {string}
               */
              type: "api_error" | "invalid_request_error";
              /** @description A message providing more details about the error. */
              message: string;
            };
          };
        };
      };
    };
  };
  /**
   * Mistral
   * @description Generate text using the Mistral family of language models. Trained by [Mistral AI](https://huggingface.co/docs/transformers/main/model_doc/mistral) and hosted on Substrate.
   */
  Mistral: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input prompts. */
          prompts: {
              /** @description Prompt to generate completions for. */
              prompt: string;
            }[];
          /**
           * Format: float
           * @description Sampling temperature to use. Higher values make the output more random; lower values make the output more deterministic.
           * @default 0.75
           */
          temperature?: number;
          /**
           * @description Maximum number of tokens to generate.
           * @default 800
           */
          max_tokens?: number;
          /**
           * @description Number of completions to generate for each prompt.
           * @default 1
           */
          num_completions?: number;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** MistralOut */
            data?: {
                /** @description Generated completion choices. */
                completions: string[];
              }[];
            /** ErrorOut */
            error?: {
              /**
               * @description The type of error returned.
               * @enum {string}
               */
              type: "api_error" | "invalid_request_error";
              /** @description A message providing more details about the error. */
              message: string;
            };
          };
        };
      };
    };
  };
  /**
   * Whisper
   * @description Transcribe audio using the Whisper family of models. Includes sentence-level segmentation, word-level alignment and speaker diarization. Trained by [Open AI](https://huggingface.co/docs/transformers/model_doc/whisper) and hosted on Substrate.
   */
  Whisper: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Input audio URL. */
          audio_url: string;
          /** @description Prompt to guide model on contents of input audio and desired output. */
          prompt?: string;
          /**
           * @description Language of input audio in ISO-639-1 format.
           * @default en
           */
          language?: string;
          /**
           * @description Align transcription to produce more accurate sentence-level timestamps and word-level timestamps. An array of word segments will be included in each sentence segment.
           * @default false
           */
          align?: boolean;
          /**
           * @description Identify speakers for each segment. Speaker IDs will be added to each output segment.
           * @default false
           */
          diarize?: boolean;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** WhisperOut */
            data?: {
                /** @description Text of segment. */
                text: string;
                /**
                 * Format: float
                 * @description Start time of segment, in seconds.
                 */
                start: number;
                /**
                 * Format: float
                 * @description End time of segment, in seconds.
                 */
                end: number;
                /** @description ID of speaker, if `diarize` is enabled. */
                speaker?: string;
                /** @description Aligned words, if `align` is enabled. */
                words?: {
                    /** @description Text of word. */
                    word: string;
                    /**
                     * Format: float
                     * @description Start time of word, in seconds.
                     */
                    start: number;
                    /**
                     * Format: float
                     * @description End time of word, in seconds.
                     */
                    end: number;
                    /** @description ID of speaker, if `diarize` is enabled. */
                    speaker?: string;
                  }[];
              }[];
            /** ErrorOut */
            error?: {
              /**
               * @description The type of error returned.
               * @enum {string}
               */
              type: "api_error" | "invalid_request_error";
              /** @description A message providing more details about the error. */
              message: string;
            };
          };
        };
      };
    };
  };
  /**
   * Jina
   * @description TODO. Trained by [Jina AI](https://huggingface.co/jinaai) and hosted on Substrate.
   */
  Jina: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Documents to embed. */
          docs: {
              /** @description Text to embed. */
              text: string;
              /** @description Document id. Required when storing embedding. */
              id?: string;
              /** @description Additional metadata to store in embedding document. */
              metadata?: Record<string, never>;
              /** @description Contents of `metadata` included to generate embedding. */
              embed_metadata_keys?: string[];
            }[];
          /** @description Vector store ID in which embedding will be stored. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** JinaOut */
            data?: {
                /** @description Embedding vector. */
                vector: string;
                /** @description Document id. */
                id?: string;
                /** @description Additional metadata stored in embedding document. */
                metadata?: Record<string, never>;
              }[];
            /** ErrorOut */
            error?: {
              /**
               * @description The type of error returned.
               * @enum {string}
               */
              type: "api_error" | "invalid_request_error";
              /** @description A message providing more details about the error. */
              message: string;
            };
          };
        };
      };
    };
  };
  /**
   * CLIP
   * @description TODO. Trained by [Open AI](https://huggingface.co/docs/transformers/model_doc/clip) and hosted on Substrate.
   */
  CLIP: {
    parameters: {
      query?: {
        undefined?: {
          /** @description Documents to embed. */
          docs: {
              /** @description Text to embed. */
              text?: string;
              /** @description URL of image to embed. */
              image_url?: string;
              /** @description Document id. Required when storing embedding. */
              id?: string;
              /** @description Additional metadata to store in embedding document. */
              metadata?: Record<string, never>;
              /** @description Contents of `metadata` included to generate embedding. */
              embed_metadata_keys?: string[];
            }[];
          /** @description Vector store ID in which embedding will be stored. */
          store?: string;
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": {
            /** CLIPOut */
            data?: {
                /** @description Embedding vector. */
                vector: string;
                /** @description Document id. */
                id?: string;
                /** @description Additional metadata stored in embedding document. */
                metadata?: Record<string, never>;
              }[];
            /** ErrorOut */
            error?: {
              /**
               * @description The type of error returned.
               * @enum {string}
               */
              type: "api_error" | "invalid_request_error";
              /** @description A message providing more details about the error. */
              message: string;
            };
          };
        };
      };
    };
  };
}
